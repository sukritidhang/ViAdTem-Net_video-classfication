{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"10k9HlTPdsSFZ6Tx75qNtNI68KOfBMmkk","authorship_tag":"ABX9TyPLQeNTTbPPALllYc8+PXUo"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["!pip install torchvision"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vXov9EvQfqQb","executionInfo":{"status":"ok","timestamp":1701687854370,"user_tz":0,"elapsed":39631,"user":{"displayName":"Sukriti Dhang","userId":"17489705121618565895"}},"outputId":"69d25f15-242c-4a73-b048-0c83290df2bb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting torchvision"]},{"output_type":"stream","name":"stderr","text":["WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\sukri\\anaconda3\\envs\\tf-gpu\\lib\\site-packages)\n","WARNING: Ignoring invalid distribution -cipy (c:\\users\\sukri\\anaconda3\\envs\\tf-gpu\\lib\\site-packages)\n","WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\sukri\\anaconda3\\envs\\tf-gpu\\lib\\site-packages)\n","WARNING: Ignoring invalid distribution -cipy (c:\\users\\sukri\\anaconda3\\envs\\tf-gpu\\lib\\site-packages)\n","WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\sukri\\anaconda3\\envs\\tf-gpu\\lib\\site-packages)\n","WARNING: Ignoring invalid distribution -cipy (c:\\users\\sukri\\anaconda3\\envs\\tf-gpu\\lib\\site-packages)\n","WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\sukri\\anaconda3\\envs\\tf-gpu\\lib\\site-packages)\n","WARNING: Ignoring invalid distribution -cipy (c:\\users\\sukri\\anaconda3\\envs\\tf-gpu\\lib\\site-packages)\n","WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\sukri\\anaconda3\\envs\\tf-gpu\\lib\\site-packages)\n","WARNING: Ignoring invalid distribution -cipy (c:\\users\\sukri\\anaconda3\\envs\\tf-gpu\\lib\\site-packages)\n","WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\sukri\\anaconda3\\envs\\tf-gpu\\lib\\site-packages)\n","WARNING: Ignoring invalid distribution -cipy (c:\\users\\sukri\\anaconda3\\envs\\tf-gpu\\lib\\site-packages)\n","WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\sukri\\anaconda3\\envs\\tf-gpu\\lib\\site-packages)\n","WARNING: Ignoring invalid distribution -cipy (c:\\users\\sukri\\anaconda3\\envs\\tf-gpu\\lib\\site-packages)\n","WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\sukri\\anaconda3\\envs\\tf-gpu\\lib\\site-packages)\n","WARNING: Ignoring invalid distribution -cipy (c:\\users\\sukri\\anaconda3\\envs\\tf-gpu\\lib\\site-packages)\n","WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\sukri\\anaconda3\\envs\\tf-gpu\\lib\\site-packages)\n","WARNING: Ignoring invalid distribution -cipy (c:\\users\\sukri\\anaconda3\\envs\\tf-gpu\\lib\\site-packages)\n","WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\sukri\\anaconda3\\envs\\tf-gpu\\lib\\site-packages)\n","WARNING: Ignoring invalid distribution -cipy (c:\\users\\sukri\\anaconda3\\envs\\tf-gpu\\lib\\site-packages)\n","WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\sukri\\anaconda3\\envs\\tf-gpu\\lib\\site-packages)\n","WARNING: Ignoring invalid distribution -cipy (c:\\users\\sukri\\anaconda3\\envs\\tf-gpu\\lib\\site-packages)\n"]},{"output_type":"stream","name":"stdout","text":["\n","  Downloading torchvision-0.16.1-cp39-cp39-win_amd64.whl (1.1 MB)\n","     ---------------------------------------- 0.0/1.1 MB ? eta -:--:--\n","     ---------------------------------------- 0.0/1.1 MB ? eta -:--:--\n","     - -------------------------------------- 0.0/1.1 MB ? eta -:--:--\n","     ---------- ----------------------------- 0.3/1.1 MB 6.3 MB/s eta 0:00:01\n","     ------------------------------------- -- 1.1/1.1 MB 13.7 MB/s eta 0:00:01\n","     ---------------------------------------- 1.1/1.1 MB 12.0 MB/s eta 0:00:00\n","Collecting torch==2.1.1\n","  Downloading torch-2.1.1-cp39-cp39-win_amd64.whl (192.2 MB)\n","     ---------------------------------------- 0.0/192.2 MB ? eta -:--:--\n","     --------------------------------------- 1.4/192.2 MB 29.0 MB/s eta 0:00:07\n","     --------------------------------------- 2.4/192.2 MB 30.5 MB/s eta 0:00:07\n","      -------------------------------------- 3.4/192.2 MB 27.1 MB/s eta 0:00:07\n","      -------------------------------------- 4.5/192.2 MB 28.7 MB/s eta 0:00:07\n","     - ------------------------------------- 5.5/192.2 MB 25.2 MB/s eta 0:00:08\n","     - ------------------------------------- 7.0/192.2 MB 28.1 MB/s eta 0:00:07\n","     - ------------------------------------- 8.1/192.2 MB 28.8 MB/s eta 0:00:07\n","     - ------------------------------------- 9.2/192.2 MB 26.8 MB/s eta 0:00:07\n","     -- ----------------------------------- 10.2/192.2 MB 27.1 MB/s eta 0:00:07\n","     -- ----------------------------------- 10.2/192.2 MB 27.1 MB/s eta 0:00:07\n","     -- ----------------------------------- 10.2/192.2 MB 27.1 MB/s eta 0:00:07\n","     -- ----------------------------------- 12.8/192.2 MB 25.2 MB/s eta 0:00:08\n","     -- ----------------------------------- 14.3/192.2 MB 25.2 MB/s eta 0:00:08\n","     -- ----------------------------------- 15.1/192.2 MB 26.2 MB/s eta 0:00:07\n","     --- ---------------------------------- 16.2/192.2 MB 26.2 MB/s eta 0:00:07\n","     --- ---------------------------------- 17.1/192.2 MB 25.1 MB/s eta 0:00:07\n","     --- ---------------------------------- 17.6/192.2 MB 24.2 MB/s eta 0:00:08\n","     --- ---------------------------------- 17.6/192.2 MB 24.2 MB/s eta 0:00:08\n","     --- ---------------------------------- 20.0/192.2 MB 25.1 MB/s eta 0:00:07\n","     ---- --------------------------------- 21.1/192.2 MB 28.4 MB/s eta 0:00:07\n","     ---- --------------------------------- 22.2/192.2 MB 26.2 MB/s eta 0:00:07\n","     ---- --------------------------------- 23.1/192.2 MB 26.2 MB/s eta 0:00:07\n","     ---- --------------------------------- 23.9/192.2 MB 25.2 MB/s eta 0:00:07\n","     ---- --------------------------------- 24.8/192.2 MB 24.3 MB/s eta 0:00:07\n","     ----- -------------------------------- 25.7/192.2 MB 23.4 MB/s eta 0:00:08\n","     ----- -------------------------------- 26.8/192.2 MB 24.2 MB/s eta 0:00:07\n","     ----- -------------------------------- 27.5/192.2 MB 23.4 MB/s eta 0:00:08\n","     ----- -------------------------------- 28.7/192.2 MB 26.2 MB/s eta 0:00:07\n","     ----- -------------------------------- 29.8/192.2 MB 23.4 MB/s eta 0:00:07\n","     ------ ------------------------------- 30.4/192.2 MB 24.2 MB/s eta 0:00:07\n","     ------ ------------------------------- 31.1/192.2 MB 21.8 MB/s eta 0:00:08\n","     ------ ------------------------------- 32.0/192.2 MB 22.6 MB/s eta 0:00:08\n","     ------ ------------------------------- 32.9/192.2 MB 21.8 MB/s eta 0:00:08\n","     ------ ------------------------------- 33.7/192.2 MB 21.8 MB/s eta 0:00:08\n","     ------ ------------------------------- 34.4/192.2 MB 21.9 MB/s eta 0:00:08\n","     ------ ------------------------------- 35.4/192.2 MB 22.6 MB/s eta 0:00:07\n","     ------- ------------------------------ 36.2/192.2 MB 22.6 MB/s eta 0:00:07\n","     ------- ------------------------------ 37.1/192.2 MB 21.9 MB/s eta 0:00:08\n","     ------- ------------------------------ 37.9/192.2 MB 21.8 MB/s eta 0:00:08\n","     ------- ------------------------------ 38.9/192.2 MB 21.1 MB/s eta 0:00:08\n","     ------- ------------------------------ 39.7/192.2 MB 21.1 MB/s eta 0:00:08\n","     -------- ----------------------------- 40.5/192.2 MB 21.8 MB/s eta 0:00:07\n","     -------- ----------------------------- 41.5/192.2 MB 22.6 MB/s eta 0:00:07\n","     -------- ----------------------------- 42.5/192.2 MB 23.4 MB/s eta 0:00:07\n","     -------- ----------------------------- 43.8/192.2 MB 24.2 MB/s eta 0:00:07\n","     -------- ----------------------------- 44.8/192.2 MB 24.2 MB/s eta 0:00:07\n","     --------- ---------------------------- 45.7/192.2 MB 23.4 MB/s eta 0:00:07\n","     --------- ---------------------------- 46.7/192.2 MB 23.4 MB/s eta 0:00:07\n","     --------- ---------------------------- 47.7/192.2 MB 25.2 MB/s eta 0:00:06\n","     --------- ---------------------------- 48.8/192.2 MB 24.2 MB/s eta 0:00:06\n","     --------- ---------------------------- 49.9/192.2 MB 26.2 MB/s eta 0:00:06\n","     ---------- --------------------------- 50.8/192.2 MB 25.2 MB/s eta 0:00:06\n","     ---------- --------------------------- 51.4/192.2 MB 25.2 MB/s eta 0:00:06\n","     ---------- --------------------------- 52.3/192.2 MB 25.2 MB/s eta 0:00:06\n","     ---------- --------------------------- 53.1/192.2 MB 24.2 MB/s eta 0:00:06\n","     ---------- --------------------------- 54.0/192.2 MB 24.3 MB/s eta 0:00:06\n","     ---------- --------------------------- 54.8/192.2 MB 24.2 MB/s eta 0:00:06\n","     ----------- -------------------------- 56.0/192.2 MB 24.2 MB/s eta 0:00:06\n","     ----------- -------------------------- 56.8/192.2 MB 24.2 MB/s eta 0:00:06\n","     ----------- -------------------------- 57.7/192.2 MB 24.2 MB/s eta 0:00:06\n","     ----------- -------------------------- 58.6/192.2 MB 24.2 MB/s eta 0:00:06\n","     ----------- -------------------------- 59.5/192.2 MB 23.4 MB/s eta 0:00:06\n","     ----------- -------------------------- 60.2/192.2 MB 23.4 MB/s eta 0:00:06\n","     ------------ ------------------------- 61.3/192.2 MB 23.4 MB/s eta 0:00:06\n","     ------------ ------------------------- 62.3/192.2 MB 23.4 MB/s eta 0:00:06\n","     ------------ ------------------------- 62.9/192.2 MB 23.4 MB/s eta 0:00:06\n","     ------------ ------------------------- 63.8/192.2 MB 22.6 MB/s eta 0:00:06\n","     ------------ ------------------------- 64.5/192.2 MB 24.2 MB/s eta 0:00:06\n","     ------------ ------------------------- 65.6/192.2 MB 23.4 MB/s eta 0:00:06\n","     ------------- ------------------------ 66.7/192.2 MB 24.2 MB/s eta 0:00:06\n","     ------------- ------------------------ 67.8/192.2 MB 23.4 MB/s eta 0:00:06\n","     ------------- ------------------------ 68.6/192.2 MB 23.4 MB/s eta 0:00:06\n","     ------------- ------------------------ 69.8/192.2 MB 23.4 MB/s eta 0:00:06\n","     ------------- ------------------------ 70.6/192.2 MB 23.4 MB/s eta 0:00:06\n","     -------------- ----------------------- 71.6/192.2 MB 23.4 MB/s eta 0:00:06\n","     -------------- ----------------------- 72.6/192.2 MB 23.4 MB/s eta 0:00:06\n","     -------------- ----------------------- 73.5/192.2 MB 23.4 MB/s eta 0:00:06\n","     -------------- ----------------------- 74.4/192.2 MB 23.4 MB/s eta 0:00:06\n","     -------------- ----------------------- 75.2/192.2 MB 24.2 MB/s eta 0:00:05\n","     --------------- ---------------------- 76.0/192.2 MB 23.4 MB/s eta 0:00:05\n","     --------------- ---------------------- 76.7/192.2 MB 21.9 MB/s eta 0:00:06\n","     --------------- ---------------------- 77.5/192.2 MB 21.8 MB/s eta 0:00:06\n","     --------------- ---------------------- 78.5/192.2 MB 21.8 MB/s eta 0:00:06\n","     --------------- ---------------------- 79.3/192.2 MB 22.6 MB/s eta 0:00:05\n","     --------------- ---------------------- 80.3/192.2 MB 23.4 MB/s eta 0:00:05\n","     ---------------- --------------------- 81.4/192.2 MB 22.6 MB/s eta 0:00:05\n","     ---------------- --------------------- 82.6/192.2 MB 23.4 MB/s eta 0:00:05\n","     ---------------- --------------------- 83.3/192.2 MB 23.4 MB/s eta 0:00:05\n","     ---------------- --------------------- 84.0/192.2 MB 22.6 MB/s eta 0:00:05\n","     ---------------- --------------------- 84.7/192.2 MB 22.6 MB/s eta 0:00:05\n","     ----------------- -------------------- 86.2/192.2 MB 21.9 MB/s eta 0:00:05\n","     ----------------- -------------------- 87.1/192.2 MB 22.5 MB/s eta 0:00:05\n","     ----------------- -------------------- 88.0/192.2 MB 22.6 MB/s eta 0:00:05\n","     ----------------- -------------------- 89.0/192.2 MB 21.8 MB/s eta 0:00:05\n","     ----------------- -------------------- 89.8/192.2 MB 21.8 MB/s eta 0:00:05\n","     ----------------- -------------------- 90.6/192.2 MB 21.9 MB/s eta 0:00:05\n","     ------------------ ------------------- 91.3/192.2 MB 21.1 MB/s eta 0:00:05\n","     ------------------ ------------------- 92.0/192.2 MB 19.9 MB/s eta 0:00:06\n","     ------------------ ------------------- 92.7/192.2 MB 19.9 MB/s eta 0:00:06\n","     ------------------ ------------------- 93.5/192.2 MB 19.8 MB/s eta 0:00:05\n","     ------------------ ------------------- 94.4/192.2 MB 20.5 MB/s eta 0:00:05\n","     ------------------ ------------------- 95.2/192.2 MB 21.1 MB/s eta 0:00:05\n","     ------------------ ------------------- 96.1/192.2 MB 20.5 MB/s eta 0:00:05\n","     ------------------- ------------------ 97.0/192.2 MB 19.8 MB/s eta 0:00:05\n","     ------------------- ------------------ 97.7/192.2 MB 20.5 MB/s eta 0:00:05\n","     ------------------- ------------------ 98.4/192.2 MB 20.5 MB/s eta 0:00:05\n","     ------------------- ------------------ 99.1/192.2 MB 19.8 MB/s eta 0:00:05\n","     ------------------- ----------------- 100.0/192.2 MB 19.8 MB/s eta 0:00:05\n","     ------------------- ----------------- 100.9/192.2 MB 20.5 MB/s eta 0:00:05\n","     ------------------- ----------------- 101.7/192.2 MB 20.5 MB/s eta 0:00:05\n","     ------------------- ----------------- 102.5/192.2 MB 21.1 MB/s eta 0:00:05\n","     ------------------- ----------------- 103.4/192.2 MB 21.1 MB/s eta 0:00:05\n","     -------------------- ---------------- 104.1/192.2 MB 21.1 MB/s eta 0:00:05\n","     -------------------- ---------------- 104.9/192.2 MB 21.1 MB/s eta 0:00:05\n","     -------------------- ---------------- 105.8/192.2 MB 21.8 MB/s eta 0:00:04\n","     -------------------- ---------------- 107.0/192.2 MB 21.8 MB/s eta 0:00:04\n","     -------------------- ---------------- 108.1/192.2 MB 23.4 MB/s eta 0:00:04\n","     -------------------- ---------------- 108.9/192.2 MB 22.6 MB/s eta 0:00:04\n","     --------------------- --------------- 110.1/192.2 MB 23.4 MB/s eta 0:00:04\n","     --------------------- --------------- 111.1/192.2 MB 22.6 MB/s eta 0:00:04\n","     --------------------- --------------- 112.1/192.2 MB 22.6 MB/s eta 0:00:04\n","     --------------------- --------------- 112.6/192.2 MB 22.6 MB/s eta 0:00:04\n","     --------------------- --------------- 113.4/192.2 MB 21.8 MB/s eta 0:00:04\n","     ---------------------- -------------- 114.4/192.2 MB 22.6 MB/s eta 0:00:04\n","     ---------------------- -------------- 115.1/192.2 MB 21.9 MB/s eta 0:00:04\n","     ---------------------- -------------- 115.9/192.2 MB 21.1 MB/s eta 0:00:04\n","     ---------------------- -------------- 116.9/192.2 MB 21.1 MB/s eta 0:00:04\n","     ---------------------- -------------- 117.8/192.2 MB 21.1 MB/s eta 0:00:04\n","     ---------------------- -------------- 118.8/192.2 MB 21.1 MB/s eta 0:00:04\n","     ----------------------- ------------- 119.7/192.2 MB 21.8 MB/s eta 0:00:04\n","     ----------------------- ------------- 120.6/192.2 MB 21.8 MB/s eta 0:00:04\n","     ----------------------- ------------- 121.3/192.2 MB 22.6 MB/s eta 0:00:04\n","     ----------------------- ------------- 122.3/192.2 MB 23.4 MB/s eta 0:00:03\n","     ----------------------- ------------- 123.0/192.2 MB 23.4 MB/s eta 0:00:03\n","     ----------------------- ------------- 123.9/192.2 MB 22.6 MB/s eta 0:00:04\n","     ------------------------ ------------ 124.8/192.2 MB 24.2 MB/s eta 0:00:03\n","     ------------------------ ------------ 125.7/192.2 MB 23.4 MB/s eta 0:00:03\n","     ------------------------ ------------ 126.4/192.2 MB 23.4 MB/s eta 0:00:03\n","     ------------------------ ------------ 127.5/192.2 MB 24.2 MB/s eta 0:00:03\n","     ------------------------ ------------ 128.6/192.2 MB 24.2 MB/s eta 0:00:03\n","     ------------------------ ------------ 129.6/192.2 MB 24.2 MB/s eta 0:00:03\n","     ------------------------- ----------- 130.8/192.2 MB 24.2 MB/s eta 0:00:03\n","     ------------------------- ----------- 132.3/192.2 MB 26.2 MB/s eta 0:00:03\n","     ------------------------- ----------- 133.6/192.2 MB 26.2 MB/s eta 0:00:03\n","     ------------------------- ----------- 134.8/192.2 MB 25.2 MB/s eta 0:00:03\n","     -------------------------- ---------- 135.8/192.2 MB 25.2 MB/s eta 0:00:03\n","     -------------------------- ---------- 136.8/192.2 MB 27.3 MB/s eta 0:00:03\n","     -------------------------- ---------- 137.6/192.2 MB 26.2 MB/s eta 0:00:03\n","     -------------------------- ---------- 138.9/192.2 MB 25.2 MB/s eta 0:00:03\n","     -------------------------- ---------- 139.8/192.2 MB 25.2 MB/s eta 0:00:03\n","     --------------------------- --------- 140.7/192.2 MB 26.2 MB/s eta 0:00:02\n","     --------------------------- --------- 141.8/192.2 MB 25.2 MB/s eta 0:00:03\n","     --------------------------- --------- 142.7/192.2 MB 25.2 MB/s eta 0:00:02\n","     --------------------------- --------- 143.7/192.2 MB 24.2 MB/s eta 0:00:03\n","     --------------------------- --------- 144.6/192.2 MB 24.2 MB/s eta 0:00:02\n","     --------------------------- --------- 145.5/192.2 MB 24.2 MB/s eta 0:00:02\n","     ---------------------------- -------- 146.4/192.2 MB 24.2 MB/s eta 0:00:02\n","     ---------------------------- -------- 147.3/192.2 MB 24.2 MB/s eta 0:00:02\n","     ---------------------------- -------- 148.2/192.2 MB 24.2 MB/s eta 0:00:02\n","     ---------------------------- -------- 149.1/192.2 MB 25.2 MB/s eta 0:00:02\n","     ---------------------------- -------- 150.1/192.2 MB 24.2 MB/s eta 0:00:02\n","     ----------------------------- ------- 151.1/192.2 MB 24.2 MB/s eta 0:00:02\n","     ----------------------------- ------- 152.0/192.2 MB 24.2 MB/s eta 0:00:02\n","     ----------------------------- ------- 153.0/192.2 MB 25.1 MB/s eta 0:00:02\n","     ----------------------------- ------- 153.9/192.2 MB 25.2 MB/s eta 0:00:02\n","     ----------------------------- ------- 155.0/192.2 MB 24.2 MB/s eta 0:00:02\n","     ------------------------------ ------ 155.9/192.2 MB 24.2 MB/s eta 0:00:02\n","     ------------------------------ ------ 156.8/192.2 MB 25.2 MB/s eta 0:00:02\n","     ------------------------------ ------ 157.9/192.2 MB 25.1 MB/s eta 0:00:02\n","     ------------------------------ ------ 159.0/192.2 MB 26.2 MB/s eta 0:00:02\n","     ------------------------------ ------ 160.0/192.2 MB 25.2 MB/s eta 0:00:02\n","     ------------------------------ ------ 161.0/192.2 MB 26.2 MB/s eta 0:00:02\n","     ------------------------------- ----- 162.0/192.2 MB 25.2 MB/s eta 0:00:02\n","     ------------------------------- ----- 162.9/192.2 MB 25.2 MB/s eta 0:00:02\n","     ------------------------------- ----- 164.2/192.2 MB 26.2 MB/s eta 0:00:02\n","     ------------------------------- ----- 165.1/192.2 MB 24.2 MB/s eta 0:00:02\n","     ------------------------------- ----- 166.2/192.2 MB 24.3 MB/s eta 0:00:02\n","     -------------------------------- ---- 167.2/192.2 MB 26.2 MB/s eta 0:00:01\n","     -------------------------------- ---- 168.1/192.2 MB 24.2 MB/s eta 0:00:01\n","     -------------------------------- ---- 169.2/192.2 MB 24.2 MB/s eta 0:00:01\n","     -------------------------------- ---- 170.4/192.2 MB 25.1 MB/s eta 0:00:01\n","     -------------------------------- ---- 171.3/192.2 MB 25.2 MB/s eta 0:00:01\n","     --------------------------------- --- 172.3/192.2 MB 25.2 MB/s eta 0:00:01\n","     --------------------------------- --- 173.3/192.2 MB 26.2 MB/s eta 0:00:01\n","     --------------------------------- --- 174.4/192.2 MB 25.2 MB/s eta 0:00:01\n","     --------------------------------- --- 175.4/192.2 MB 25.2 MB/s eta 0:00:01\n","     --------------------------------- --- 176.4/192.2 MB 24.2 MB/s eta 0:00:01\n","     ---------------------------------- -- 177.5/192.2 MB 24.2 MB/s eta 0:00:01\n","     ---------------------------------- -- 178.5/192.2 MB 25.2 MB/s eta 0:00:01\n","     ---------------------------------- -- 179.5/192.2 MB 25.1 MB/s eta 0:00:01\n","     ---------------------------------- -- 180.5/192.2 MB 24.2 MB/s eta 0:00:01\n","     ---------------------------------- -- 181.5/192.2 MB 24.2 MB/s eta 0:00:01\n","     ----------------------------------- - 182.4/192.2 MB 25.2 MB/s eta 0:00:01\n","     ----------------------------------- - 183.4/192.2 MB 23.4 MB/s eta 0:00:01\n","     ----------------------------------- - 184.4/192.2 MB 23.4 MB/s eta 0:00:01\n","     ----------------------------------- - 185.5/192.2 MB 25.2 MB/s eta 0:00:01\n","     ----------------------------------- - 186.4/192.2 MB 23.4 MB/s eta 0:00:01\n","     ------------------------------------  187.7/192.2 MB 24.3 MB/s eta 0:00:01\n","     ------------------------------------  188.7/192.2 MB 25.2 MB/s eta 0:00:01\n","     ------------------------------------  189.8/192.2 MB 25.2 MB/s eta 0:00:01\n","     ------------------------------------  190.8/192.2 MB 25.2 MB/s eta 0:00:01\n","     ------------------------------------  191.8/192.2 MB 26.2 MB/s eta 0:00:01\n","     ------------------------------------  192.2/192.2 MB 25.2 MB/s eta 0:00:01\n","     ------------------------------------  192.2/192.2 MB 25.2 MB/s eta 0:00:01\n","     ------------------------------------  192.2/192.2 MB 25.2 MB/s eta 0:00:01\n","     ------------------------------------  192.2/192.2 MB 25.2 MB/s eta 0:00:01\n","     ------------------------------------  192.2/192.2 MB 25.2 MB/s eta 0:00:01\n","     ------------------------------------- 192.2/192.2 MB 14.2 MB/s eta 0:00:00\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\sukri\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from torchvision) (9.4.0)\n","Requirement already satisfied: numpy in c:\\users\\sukri\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from torchvision) (1.23.5)\n","Requirement already satisfied: requests in c:\\users\\sukri\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from torchvision) (2.28.1)\n","Requirement already satisfied: fsspec in c:\\users\\sukri\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from torch==2.1.1->torchvision) (2022.11.0)\n","Requirement already satisfied: jinja2 in c:\\users\\sukri\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from torch==2.1.1->torchvision) (3.1.2)\n","Collecting sympy\n","  Downloading sympy-1.12-py3-none-any.whl (5.7 MB)\n","     ---------------------------------------- 0.0/5.7 MB ? eta -:--:--\n","     ------- -------------------------------- 1.1/5.7 MB 24.2 MB/s eta 0:00:01\n","     --------------- ------------------------ 2.2/5.7 MB 23.5 MB/s eta 0:00:01\n","     ---------------------- ----------------- 3.3/5.7 MB 30.1 MB/s eta 0:00:01\n","     --------------------------- ------------ 4.0/5.7 MB 25.5 MB/s eta 0:00:01\n","     ------------------------------------ --- 5.2/5.7 MB 23.9 MB/s eta 0:00:01\n","     ---------------------------------------- 5.7/5.7 MB 24.5 MB/s eta 0:00:00\n","Requirement already satisfied: networkx in c:\\users\\sukri\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from torch==2.1.1->torchvision) (2.8.4)\n","Requirement already satisfied: typing-extensions in c:\\users\\sukri\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from torch==2.1.1->torchvision) (4.4.0)\n","Collecting filelock\n","  Downloading filelock-3.13.1-py3-none-any.whl (11 kB)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\sukri\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from requests->torchvision) (1.26.14)\n","Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\sukri\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from requests->torchvision) (2.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sukri\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from requests->torchvision) (2023.5.7)\n","Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sukri\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from requests->torchvision) (3.4)\n","Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\sukri\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from jinja2->torch==2.1.1->torchvision) (2.1.1)\n","Collecting mpmath>=0.19\n","  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n","     ---------------------------------------- 0.0/536.2 kB ? eta -:--:--\n","     ------------------------------------- 536.2/536.2 kB 32.9 MB/s eta 0:00:00\n","Installing collected packages: mpmath, sympy, filelock, torch, torchvision\n","Successfully installed filelock-3.13.1 mpmath-1.3.0 sympy-1.12 torch-2.1.1 torchvision-0.16.1\n"]}]},{"cell_type":"code","execution_count":1,"metadata":{"id":"9kLYCpNVfzeQ","executionInfo":{"status":"ok","timestamp":1703953599136,"user_tz":0,"elapsed":7665,"user":{"displayName":"Sukriti Dhang","userId":"17489705121618565895"}}},"outputs":[],"source":["#import necessary libraries\n","\n","import matplotlib.pyplot as plt\n","import torch\n","import torchvision\n","\n","from torch import nn\n","from torchvision import transforms\n"]},{"cell_type":"code","source":["'''\n","import tensorflow as tf\n","from tensorflow.python.client import device_lib\n","\n","# Check GPU availability and set the device accordingly\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","print(\"PyTorch Device:\", device)\n","\n","# Check TensorFlow version\n","tf_version = tf.__version__\n","print(\"TensorFlow version:\", tf_version)\n","\n","# Print GPU information from TensorFlow\n","device_name = tf.test.gpu_device_name()\n","print('Found GPU at: {}'.format(device_name))\n","\n","# Set PyTorch device to GPU if available\n","torch_device = torch.device(device)\n","print(\"PyTorch Device (after setting):\", torch_device)\n","\n","# Now, you can use the PyTorch device for operations\n","tensor_on_gpu = torch.randn(3, 3).to(torch_device)\n","tensor_on_gpu\n","\n","\n","# Move a PyTorch model to the GPU\n","#model.to(torch_device)\n","'''"],"metadata":{"id":"qhY4xYumExY0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1702032922828,"user_tz":0,"elapsed":6925,"user":{"displayName":"Sukriti Dhang","userId":"17489705121618565895"}},"outputId":"8cea39fd-3412-49a7-abd5-31264c28b835"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["PyTorch Device: cpu\n","TensorFlow version: 2.5.0\n","Found GPU at: /device:GPU:0\n","PyTorch Device (after setting): cpu\n"]},{"output_type":"execute_result","data":{"text/plain":["tensor([[ 0.4370, -0.5966,  0.6961],\n","        [ 0.5541, -0.7279,  0.0381],\n","        [-0.2652,  0.8922, -1.0369]])"]},"metadata":{},"execution_count":2}]},{"cell_type":"markdown","source":["Load pre-trained ViT model"],"metadata":{"id":"d6FSEoLZh7dC"}},{"cell_type":"code","source":["# 1. Get pretrained weights for ViT-Base\n","pretrained_vit_weights = torchvision.models.ViT_B_16_Weights.DEFAULT\n","\n","# 2. Setup a ViT model instance with pretrained weights\n","pretrained_vit = torchvision.models.vit_b_16(weights=pretrained_vit_weights)#.to(device)\n","\n","\n","# 3. Freeze the base parameters\n","for parameter in pretrained_vit.parameters():\n","    parameter.requires_grad = False\n","\n","# 4. Change the classifier head\n","class_names = ['Billboard', 'No-billboard']  #Billboard'--->tensor(0), 'No-billboard'---> tensor(1)\n","\n","\n","#additional layers\n","additional_layers = nn.Sequential(\n","    #nn.Dropout(0.5),\n","    nn.Linear(in_features=1000, out_features=768),  # Another example linear layer\n","    nn.ReLU(),\n","    nn.Dropout(0.5),\n","    nn.ReLU(),\n","    nn.Dropout(0.2),\n",")\n","\n","# 5. Combine the pretrained ViT and additional layers\n","pretrained_vit_addtn = nn.Sequential(\n","    pretrained_vit,\n","    additional_layers,\n",")\n","\n","# 6. Change the classifier head\n","class_names = ['Billboard', 'No-billboard']\n","pretrained_vit_addtn.heads = nn.Linear(in_features=768, out_features=len(class_names))\n","print(pretrained_vit_addtn)\n","\n","#set_seeds()\n","#pretrained_vit.heads = nn.Linear(in_features=768, out_features=len(class_names))#.to(device)\n","#print(pretrained_vit)\n"],"metadata":{"id":"Xe6r5odlUoQI","executionInfo":{"status":"ok","timestamp":1703964618105,"user_tz":0,"elapsed":2009,"user":{"displayName":"Sukriti Dhang","userId":"17489705121618565895"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"8c45a8c3-fe66-4020-90ac-fe7216863305"},"execution_count":43,"outputs":[{"output_type":"stream","name":"stdout","text":["Sequential(\n","  (0): VisionTransformer(\n","    (conv_proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n","    (encoder): Encoder(\n","      (dropout): Dropout(p=0.0, inplace=False)\n","      (layers): Sequential(\n","        (encoder_layer_0): EncoderBlock(\n","          (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","          (self_attention): MultiheadAttention(\n","            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n","          )\n","          (dropout): Dropout(p=0.0, inplace=False)\n","          (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","          (mlp): MLPBlock(\n","            (0): Linear(in_features=768, out_features=3072, bias=True)\n","            (1): GELU(approximate='none')\n","            (2): Dropout(p=0.0, inplace=False)\n","            (3): Linear(in_features=3072, out_features=768, bias=True)\n","            (4): Dropout(p=0.0, inplace=False)\n","          )\n","        )\n","        (encoder_layer_1): EncoderBlock(\n","          (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","          (self_attention): MultiheadAttention(\n","            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n","          )\n","          (dropout): Dropout(p=0.0, inplace=False)\n","          (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","          (mlp): MLPBlock(\n","            (0): Linear(in_features=768, out_features=3072, bias=True)\n","            (1): GELU(approximate='none')\n","            (2): Dropout(p=0.0, inplace=False)\n","            (3): Linear(in_features=3072, out_features=768, bias=True)\n","            (4): Dropout(p=0.0, inplace=False)\n","          )\n","        )\n","        (encoder_layer_2): EncoderBlock(\n","          (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","          (self_attention): MultiheadAttention(\n","            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n","          )\n","          (dropout): Dropout(p=0.0, inplace=False)\n","          (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","          (mlp): MLPBlock(\n","            (0): Linear(in_features=768, out_features=3072, bias=True)\n","            (1): GELU(approximate='none')\n","            (2): Dropout(p=0.0, inplace=False)\n","            (3): Linear(in_features=3072, out_features=768, bias=True)\n","            (4): Dropout(p=0.0, inplace=False)\n","          )\n","        )\n","        (encoder_layer_3): EncoderBlock(\n","          (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","          (self_attention): MultiheadAttention(\n","            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n","          )\n","          (dropout): Dropout(p=0.0, inplace=False)\n","          (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","          (mlp): MLPBlock(\n","            (0): Linear(in_features=768, out_features=3072, bias=True)\n","            (1): GELU(approximate='none')\n","            (2): Dropout(p=0.0, inplace=False)\n","            (3): Linear(in_features=3072, out_features=768, bias=True)\n","            (4): Dropout(p=0.0, inplace=False)\n","          )\n","        )\n","        (encoder_layer_4): EncoderBlock(\n","          (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","          (self_attention): MultiheadAttention(\n","            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n","          )\n","          (dropout): Dropout(p=0.0, inplace=False)\n","          (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","          (mlp): MLPBlock(\n","            (0): Linear(in_features=768, out_features=3072, bias=True)\n","            (1): GELU(approximate='none')\n","            (2): Dropout(p=0.0, inplace=False)\n","            (3): Linear(in_features=3072, out_features=768, bias=True)\n","            (4): Dropout(p=0.0, inplace=False)\n","          )\n","        )\n","        (encoder_layer_5): EncoderBlock(\n","          (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","          (self_attention): MultiheadAttention(\n","            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n","          )\n","          (dropout): Dropout(p=0.0, inplace=False)\n","          (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","          (mlp): MLPBlock(\n","            (0): Linear(in_features=768, out_features=3072, bias=True)\n","            (1): GELU(approximate='none')\n","            (2): Dropout(p=0.0, inplace=False)\n","            (3): Linear(in_features=3072, out_features=768, bias=True)\n","            (4): Dropout(p=0.0, inplace=False)\n","          )\n","        )\n","        (encoder_layer_6): EncoderBlock(\n","          (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","          (self_attention): MultiheadAttention(\n","            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n","          )\n","          (dropout): Dropout(p=0.0, inplace=False)\n","          (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","          (mlp): MLPBlock(\n","            (0): Linear(in_features=768, out_features=3072, bias=True)\n","            (1): GELU(approximate='none')\n","            (2): Dropout(p=0.0, inplace=False)\n","            (3): Linear(in_features=3072, out_features=768, bias=True)\n","            (4): Dropout(p=0.0, inplace=False)\n","          )\n","        )\n","        (encoder_layer_7): EncoderBlock(\n","          (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","          (self_attention): MultiheadAttention(\n","            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n","          )\n","          (dropout): Dropout(p=0.0, inplace=False)\n","          (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","          (mlp): MLPBlock(\n","            (0): Linear(in_features=768, out_features=3072, bias=True)\n","            (1): GELU(approximate='none')\n","            (2): Dropout(p=0.0, inplace=False)\n","            (3): Linear(in_features=3072, out_features=768, bias=True)\n","            (4): Dropout(p=0.0, inplace=False)\n","          )\n","        )\n","        (encoder_layer_8): EncoderBlock(\n","          (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","          (self_attention): MultiheadAttention(\n","            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n","          )\n","          (dropout): Dropout(p=0.0, inplace=False)\n","          (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","          (mlp): MLPBlock(\n","            (0): Linear(in_features=768, out_features=3072, bias=True)\n","            (1): GELU(approximate='none')\n","            (2): Dropout(p=0.0, inplace=False)\n","            (3): Linear(in_features=3072, out_features=768, bias=True)\n","            (4): Dropout(p=0.0, inplace=False)\n","          )\n","        )\n","        (encoder_layer_9): EncoderBlock(\n","          (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","          (self_attention): MultiheadAttention(\n","            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n","          )\n","          (dropout): Dropout(p=0.0, inplace=False)\n","          (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","          (mlp): MLPBlock(\n","            (0): Linear(in_features=768, out_features=3072, bias=True)\n","            (1): GELU(approximate='none')\n","            (2): Dropout(p=0.0, inplace=False)\n","            (3): Linear(in_features=3072, out_features=768, bias=True)\n","            (4): Dropout(p=0.0, inplace=False)\n","          )\n","        )\n","        (encoder_layer_10): EncoderBlock(\n","          (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","          (self_attention): MultiheadAttention(\n","            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n","          )\n","          (dropout): Dropout(p=0.0, inplace=False)\n","          (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","          (mlp): MLPBlock(\n","            (0): Linear(in_features=768, out_features=3072, bias=True)\n","            (1): GELU(approximate='none')\n","            (2): Dropout(p=0.0, inplace=False)\n","            (3): Linear(in_features=3072, out_features=768, bias=True)\n","            (4): Dropout(p=0.0, inplace=False)\n","          )\n","        )\n","        (encoder_layer_11): EncoderBlock(\n","          (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","          (self_attention): MultiheadAttention(\n","            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n","          )\n","          (dropout): Dropout(p=0.0, inplace=False)\n","          (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","          (mlp): MLPBlock(\n","            (0): Linear(in_features=768, out_features=3072, bias=True)\n","            (1): GELU(approximate='none')\n","            (2): Dropout(p=0.0, inplace=False)\n","            (3): Linear(in_features=3072, out_features=768, bias=True)\n","            (4): Dropout(p=0.0, inplace=False)\n","          )\n","        )\n","      )\n","      (ln): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","    )\n","    (heads): Sequential(\n","      (head): Linear(in_features=768, out_features=1000, bias=True)\n","    )\n","  )\n","  (1): Sequential(\n","    (0): Linear(in_features=1000, out_features=768, bias=True)\n","    (1): ReLU()\n","    (2): Dropout(p=0.5, inplace=False)\n","    (3): ReLU()\n","    (4): Dropout(p=0.2, inplace=False)\n","  )\n","  (heads): Linear(in_features=768, out_features=2, bias=True)\n",")\n"]}]},{"cell_type":"code","source":["!pip install torchinfo"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AmIyahtTiBJU","executionInfo":{"status":"ok","timestamp":1703326642926,"user_tz":0,"elapsed":2086,"user":{"displayName":"Sukriti Dhang","userId":"17489705121618565895"}},"outputId":"e2afe6a6-1a20-42c4-d922-5a20c4d4799c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torchinfo in c:\\users\\sukri\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (1.8.0)\n"]},{"output_type":"stream","name":"stderr","text":["WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\sukri\\anaconda3\\envs\\tf-gpu\\lib\\site-packages)\n","WARNING: Ignoring invalid distribution -cipy (c:\\users\\sukri\\anaconda3\\envs\\tf-gpu\\lib\\site-packages)\n","WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\sukri\\anaconda3\\envs\\tf-gpu\\lib\\site-packages)\n","WARNING: Ignoring invalid distribution -cipy (c:\\users\\sukri\\anaconda3\\envs\\tf-gpu\\lib\\site-packages)\n","WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\sukri\\anaconda3\\envs\\tf-gpu\\lib\\site-packages)\n","WARNING: Ignoring invalid distribution -cipy (c:\\users\\sukri\\anaconda3\\envs\\tf-gpu\\lib\\site-packages)\n","WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\sukri\\anaconda3\\envs\\tf-gpu\\lib\\site-packages)\n","WARNING: Ignoring invalid distribution -cipy (c:\\users\\sukri\\anaconda3\\envs\\tf-gpu\\lib\\site-packages)\n","WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\sukri\\anaconda3\\envs\\tf-gpu\\lib\\site-packages)\n","WARNING: Ignoring invalid distribution -cipy (c:\\users\\sukri\\anaconda3\\envs\\tf-gpu\\lib\\site-packages)\n","WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\sukri\\anaconda3\\envs\\tf-gpu\\lib\\site-packages)\n","WARNING: Ignoring invalid distribution -cipy (c:\\users\\sukri\\anaconda3\\envs\\tf-gpu\\lib\\site-packages)\n"]}]},{"cell_type":"code","source":["from torchinfo import summary\n","\n","# Print a summary using torchinfo (uncomment for actual output)\n","summary(model=  pretrained_vit_addtn, #pretrained_vit,#\n","        input_size=(32, 3, 224, 224), # (batch_size, color_channels, height, width)\n","        # col_names=[\"input_size\"], # uncomment for smaller output\n","        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n","        col_width=20,\n","        row_settings=[\"var_names\"]\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bF4IsjLUX8Wy","executionInfo":{"status":"ok","timestamp":1703964641156,"user_tz":0,"elapsed":21215,"user":{"displayName":"Sukriti Dhang","userId":"17489705121618565895"}},"outputId":"aedef240-4c8e-4d46-d861-5706e2292cf1"},"execution_count":44,"outputs":[{"output_type":"execute_result","data":{"text/plain":["=================================================================================================================================================\n","Layer (type (var_name))                                           Input Shape          Output Shape         Param #              Trainable\n","=================================================================================================================================================\n","Sequential (Sequential)                                           [32, 3, 224, 224]    [32, 2]              --                   Partial\n","├─VisionTransformer (0)                                           [32, 3, 224, 224]    [32, 1000]           768                  False\n","│    └─Conv2d (conv_proj)                                         [32, 3, 224, 224]    [32, 768, 14, 14]    (590,592)            False\n","│    └─Encoder (encoder)                                          [32, 197, 768]       [32, 197, 768]       151,296              False\n","│    │    └─Dropout (dropout)                                     [32, 197, 768]       [32, 197, 768]       --                   --\n","│    │    └─Sequential (layers)                                   [32, 197, 768]       [32, 197, 768]       (85,054,464)         False\n","│    │    └─LayerNorm (ln)                                        [32, 197, 768]       [32, 197, 768]       (1,536)              False\n","│    └─Sequential (heads)                                         [32, 768]            [32, 1000]           --                   False\n","│    │    └─Linear (head)                                         [32, 768]            [32, 1000]           (769,000)            False\n","├─Sequential (1)                                                  [32, 1000]           [32, 768]            --                   True\n","│    └─Linear (0)                                                 [32, 1000]           [32, 768]            768,768              True\n","│    └─ReLU (1)                                                   [32, 768]            [32, 768]            --                   --\n","│    └─Dropout (2)                                                [32, 768]            [32, 768]            --                   --\n","│    └─ReLU (3)                                                   [32, 768]            [32, 768]            --                   --\n","│    └─Dropout (4)                                                [32, 768]            [32, 768]            --                   --\n","├─Linear (heads)                                                  [32, 768]            [32, 2]              1,538                True\n","=================================================================================================================================================\n","Total params: 87,337,962\n","Trainable params: 770,306\n","Non-trainable params: 86,567,656\n","Total mult-adds (G): 5.57\n","=================================================================================================================================================\n","Input size (MB): 19.27\n","Forward/backward pass size (MB): 3331.19\n","Params size (MB): 235.35\n","Estimated Total Size (MB): 3585.81\n","================================================================================================================================================="]},"metadata":{},"execution_count":44}]},{"cell_type":"code","source":["# Get automatic transforms from pretrained ViT weights\n","pretrained_vit_transforms = pretrained_vit_weights.transforms()\n","print(pretrained_vit_transforms)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tNrIPCj8U39x","executionInfo":{"status":"ok","timestamp":1703953638272,"user_tz":0,"elapsed":9,"user":{"displayName":"Sukriti Dhang","userId":"17489705121618565895"}},"outputId":"ba726167-df92-4976-df42-f948f901c288"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["ImageClassification(\n","    crop_size=[224]\n","    resize_size=[256]\n","    mean=[0.485, 0.456, 0.406]\n","    std=[0.229, 0.224, 0.225]\n","    interpolation=InterpolationMode.BILINEAR\n",")\n"]}]},{"cell_type":"markdown","source":["Load the dataset"],"metadata":{"id":"ULQK7T7WhHZf"}},{"cell_type":"code","source":["# Setup directory paths to train and test images\n","train_dir = '/python_programming/FYP_2022/billboard_dataset/train'\n","val_dir =  '/python_programming/FYP_2022/billboard_dataset/val'\n","test_dir = '/python_programming/FYP_2022/billboard_dataset/test'\n"],"metadata":{"id":"kbraIO6MCwvu","executionInfo":{"status":"ok","timestamp":1703953638376,"user_tz":0,"elapsed":13,"user":{"displayName":"Sukriti Dhang","userId":"17489705121618565895"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["from torchvision import datasets, transforms\n","from torch.utils.data import DataLoader\n","\n","def create_dataloaders(\n","    train_dir: str,\n","    val_dir: str,\n","    test_dir: str,\n","    transform: transforms.Compose,\n","    batch_size: int,\n","):\n","\n","  # Use ImageFolder to create dataset(s)\n","  train_data = datasets.ImageFolder(train_dir, transform=transform)\n","  val_data = datasets.ImageFolder(val_dir, transform=transform)\n","  test_data = datasets.ImageFolder(test_dir, transform=transform)\n","\n","  print(train_data)\n","  # Get class names\n","  class_names = train_data.classes\n","  print(val_data)\n","\n","  # Turn images into data loaders\n","  train_dataloader = DataLoader(\n","      train_data,\n","      batch_size=batch_size,\n","      shuffle=True,\n","      pin_memory=True,\n","  )\n","  val_dataloader = DataLoader(\n","      val_data,\n","      batch_size=batch_size,\n","      shuffle=False,\n","      pin_memory=True,\n","  )\n","\n","  test_dataloader = DataLoader(\n","      test_data,\n","      batch_size=batch_size,\n","      shuffle=False,\n","      pin_memory=True,\n","  )\n","\n","  return train_dataloader, val_dataloader, test_dataloader, class_names"],"metadata":{"id":"KzpRLX2IAmeu","executionInfo":{"status":"ok","timestamp":1703953646497,"user_tz":0,"elapsed":14,"user":{"displayName":"Sukriti Dhang","userId":"17489705121618565895"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["# Setup dataloaders\n","train_dataloader_pretrained, val_dataloader_pretrained, test_dataloader_pretrained,  class_names = create_dataloaders(train_dir=train_dir,\n","                                                                                                     val_dir = val_dir,\n","                                                                                                     test_dir = test_dir,\n","                                                                                                     transform=pretrained_vit_transforms,\n","                                                                                                     batch_size=16)#32\n","\n","train_dataloader_pretrained, val_dataloader_pretrained, test_dataloader_pretrained, class_names"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3cFSNwYFBilN","executionInfo":{"status":"ok","timestamp":1703953648453,"user_tz":0,"elapsed":64,"user":{"displayName":"Sukriti Dhang","userId":"17489705121618565895"}},"outputId":"769ff8d5-081b-4657-cfef-54bfb28d0e66"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Dataset ImageFolder\n","    Number of datapoints: 2000\n","    Root location: /python_programming/FYP_2022/billboard_dataset/train\n","    StandardTransform\n","Transform: ImageClassification(\n","               crop_size=[224]\n","               resize_size=[256]\n","               mean=[0.485, 0.456, 0.406]\n","               std=[0.229, 0.224, 0.225]\n","               interpolation=InterpolationMode.BILINEAR\n","           )\n","Dataset ImageFolder\n","    Number of datapoints: 1000\n","    Root location: /python_programming/FYP_2022/billboard_dataset/val\n","    StandardTransform\n","Transform: ImageClassification(\n","               crop_size=[224]\n","               resize_size=[256]\n","               mean=[0.485, 0.456, 0.406]\n","               std=[0.229, 0.224, 0.225]\n","               interpolation=InterpolationMode.BILINEAR\n","           )\n"]},{"output_type":"execute_result","data":{"text/plain":["(<torch.utils.data.dataloader.DataLoader at 0x232ee9bb0a0>,\n"," <torch.utils.data.dataloader.DataLoader at 0x232ee9bb3d0>,\n"," <torch.utils.data.dataloader.DataLoader at 0x232ee9bbb50>,\n"," ['Billboard', 'No_Billboard'])"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["\n","# Get a batch of images\n","image_batch, label_batch = next(iter(train_dataloader_pretrained))\n","\n","# Get a single image from the batch\n","image, label = image_batch[0], label_batch[0]\n","\n","\n","# View the batch shapes\n","print(image.shape, label)\n","print('label:', class_names[label])\n","\n","\n","#plt.imshow(train_dataloader_pretrained[image])\n","\n","'''\n","# Plot image with matplotlib\n","plt.imshow(image.permute(1, 2, 0)) # rearrange image dimensions to suit matplotlib [color_channels, height, width] -> [height, width, color_channels]\n","plt.title(class_names[label])\n","plt.axis(False);\n","'''"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gekx72bZq-IN","executionInfo":{"status":"ok","timestamp":1703953651257,"user_tz":0,"elapsed":692,"user":{"displayName":"Sukriti Dhang","userId":"17489705121618565895"}},"outputId":"11a4e2d0-4851-4cb8-8409-36fecc2d6780"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([3, 224, 224]) tensor(0)\n","label: Billboard\n"]},{"output_type":"execute_result","data":{"text/plain":["'\\n# Plot image with matplotlib\\nplt.imshow(image.permute(1, 2, 0)) # rearrange image dimensions to suit matplotlib [color_channels, height, width] -> [height, width, color_channels]\\nplt.title(class_names[label])\\nplt.axis(False);\\n'"]},"metadata":{},"execution_count":8}]},{"cell_type":"markdown","source":["Train the model"],"metadata":{"id":"xhtpEACqwOah"}},{"cell_type":"code","source":["import csv\n","import h5py\n","\n","from tqdm.auto import tqdm\n","from typing import Dict, List, Tuple\n","\n","def train_step(model: torch.nn.Module,\n","               dataloader: torch.utils.data.DataLoader,\n","               loss_fn: torch.nn.Module,\n","               optimizer: torch.optim.Optimizer) -> Tuple[float, float]:\n","\n","    # Put model in train mode\n","    model.train()\n","\n","    # Setup train loss and train accuracy values\n","    train_loss, train_acc = 0, 0\n","\n","    # Variables for precision, recall, and F1 score\n","    train_TP, train_FP, train_FN = 0, 0, 0\n","\n","    # Loop through data loader data batches\n","    for batch, (X, y) in enumerate(dataloader):\n","        # Send data to target device\n","        X, y = X, y #X.to(device), y.to(device)\n","\n","        # 1. Forward pass\n","        y_pred = model(X)\n","\n","        # 2. Calculate  and accumulate loss\n","        loss = loss_fn(y_pred, y)\n","        train_loss += loss.item()\n","\n","        # 3. Optimizer zero grad\n","        optimizer.zero_grad()\n","\n","        # 4. Loss backward\n","        loss.backward()\n","\n","        # 5. Optimizer step\n","        optimizer.step()\n","\n","        # Calculate and accumulate accuracy metric across all batches\n","        y_pred_class = torch.argmax(torch.softmax(y_pred, dim=1), dim=1)\n","        train_acc += (y_pred_class == y).sum().item()/len(y_pred)\n","\n","        # Update TP, FP, FN for precision, recall, and F1 score\n","        train_TP += ((y_pred_class == y) & (y == 1)).sum().item()\n","        train_FP += ((y_pred_class != y) & (y == 0)).sum().item()\n","        train_FN += ((y_pred_class != y) & (y == 1)).sum().item()\n","\n","    # Adjust metrics to get average loss and accuracy per batch\n","    train_loss = train_loss / len(dataloader)\n","    train_acc = train_acc / len(dataloader)\n","\n","    # Calculate precision, recall, and F1 score\n","    train_precision = train_TP / (train_TP + train_FP + 1e-12)\n","    train_recall = train_TP / (train_TP + train_FN + 1e-12)\n","    train_f1_score = 2 * (train_precision * train_recall) / (train_precision + train_recall + 1e-12)\n","\n","    return train_loss, train_acc, train_precision, train_recall, train_f1_score\n","\n","def val_step(model: torch.nn.Module,\n","              dataloader: torch.utils.data.DataLoader,\n","              loss_fn: torch.nn.Module) -> Tuple[float, float]:\n","\n","    # Put model in eval mode\n","    model.eval()\n","\n","    # Setup test loss and test accuracy values\n","    val_loss, val_acc = 0, 0\n","\n","    # Variables for precision, recall, and F1 score\n","    val_TP, val_FP, val_FN = 0, 0, 0\n","\n","    # Turn on inference context manager\n","    with torch.inference_mode():\n","        # Loop through DataLoader batches\n","        for batch, (X, y) in enumerate(dataloader):\n","            # Send data to target device\n","            X, y = X, y #X.to(device), y.to(device)\n","\n","            # 1. Forward pass\n","            val_pred_logits = model(X)\n","\n","            # 2. Calculate and accumulate loss\n","            loss = loss_fn(val_pred_logits, y)\n","            val_loss += loss.item()\n","\n","            # Calculate and accumulate accuracy\n","            val_pred_labels = val_pred_logits.argmax(dim=1)\n","            val_acc += ((val_pred_labels == y).sum().item()/len(val_pred_labels))\n","\n","            # Update TP, FP, FN for precision, recall, and F1 score\n","            val_TP += ((val_pred_labels == y) & (y == 1)).sum().item()\n","            val_FP += ((val_pred_labels != y) & (y == 0)).sum().item()\n","            val_FN += ((val_pred_labels != y) & (y == 1)).sum().item()\n","\n","    # Adjust metrics to get average loss and accuracy per batch\n","    val_loss = val_loss / len(dataloader)\n","    val_acc = val_acc / len(dataloader)\n","\n","    # Calculate precision, recall, and F1 score\n","    val_precision = val_TP / (val_TP + val_FP + 1e-12)\n","    val_recall = val_TP / (val_TP + val_FN + 1e-12)\n","    val_f1_score = 2 * (val_precision * val_recall) / (val_precision + val_recall + 1e-12)\n","\n","    return val_loss, val_acc, val_precision, val_recall, val_f1_score"],"metadata":{"id":"0DfMOS57iXAR","executionInfo":{"status":"ok","timestamp":1703953652763,"user_tz":0,"elapsed":179,"user":{"displayName":"Sukriti Dhang","userId":"17489705121618565895"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"a676ea02-781e-469b-b021-9430f9cb5129"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stderr","text":["C:\\Users\\sukri\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]}]},{"cell_type":"code","source":["def train(model: torch.nn.Module,\n","          train_dataloader: torch.utils.data.DataLoader,\n","          val_dataloader: torch.utils.data.DataLoader,\n","          optimizer: torch.optim.Optimizer,\n","          loss_fn: torch.nn.Module,\n","          epochs: int,\n","          result_csv_path: str = 'results.csv',\n","          model_save_path: str = 'model.pt') -> Dict[str, List]:\n","\n","    # Create empty results dictionary\n","    results = {\"train_loss\": [],\n","               \"train_acc\": [],\n","               \"train_precision\": [],\n","               \"train_recall\": [],\n","               \"train_f1_score\": [],\n","               \"val_loss\": [],\n","               \"val_acc\": [],\n","               \"val_precision\": [],\n","               \"val_recall\": [],\n","               \"val_f1_score\": []\n","    }\n","\n","    # Loop through training and testing steps for a number of epochs\n","    for epoch in tqdm(range(epochs)):\n","        train_loss, train_acc, train_precision, train_recall, train_f1_score = train_step(model=model,\n","                                          dataloader=train_dataloader,\n","                                          loss_fn=loss_fn,\n","                                          optimizer=optimizer)\n","        val_loss, val_acc, val_precision, val_recall, val_f1_score = val_step(model=model,\n","                                        dataloader=val_dataloader,\n","                                        loss_fn=loss_fn)\n","\n","        # Print out what's happening\n","        print(\n","            f\"Epoch: {epoch + 1} | \"\n","            f\"train_loss: {train_loss:.4f} | \"\n","            f\"train_acc: {train_acc:.4f} | \"\n","            f\"train_precision:{train_precision:.4f} |\"\n","            f\"train_recall:{train_recall:.4f} |\"\n","            f\"train_f1_score:{train_f1_score:.4f} |\"\n","            f\"val_loss: {val_loss:.4f} | \"\n","            f\"val_acc: {val_acc:.4f} |\"\n","            f\"val_precision:{val_precision:.4f} |\"\n","            f\"val_recall:{val_recall:.4f} |\"\n","            f\"val_f1_score:{val_f1_score:.4f}\"\n","        )\n","\n","        # Update results dictionary\n","        results[\"train_loss\"].append(train_loss)\n","        results[\"train_acc\"].append(train_acc)\n","        results[\"train_precision\"].append(train_precision)\n","        results[\"train_recall\"].append(train_recall)\n","        results[\"train_f1_score\"].append(train_f1_score)\n","        results[\"val_loss\"].append(val_loss)\n","        results[\"val_acc\"].append(val_acc)\n","        results[\"val_precision\"].append(val_precision)\n","        results[\"val_recall\"].append(val_recall)\n","        results[\"val_f1_score\"].append(val_f1_score)\n","\n","\n","    # Save results to CSV\n","    with open(result_csv_path, 'w', newline='') as csvfile:\n","        csvwriter = csv.writer(csvfile)\n","        csvwriter.writerow([\"Epoch\", \"Train Loss\", \"Train Acc\",\"train_precision\", \"train_recall\", \"train_f1_score\",   \"Val Loss\", \"Val Acc\", \"val_precision\",\"val_recall\",\"val_f1_score\" ])\n","        for epoch, train_loss, train_acc, val_loss, val_acc in zip(range(1, epochs + 1),\n","                                                                    results[\"train_loss\"],\n","                                                                    results[\"train_acc\"],\n","                                                                    results[\"train_precision\"],\n","                                                                    results[\"train_recall\"],\n","                                                                    results[\"train_f1_score\"],\n","                                                                    results[\"val_loss\"],\n","                                                                    results[\"val_acc\"],\n","                                                                    results[\"val_precision\"],\n","                                                                    results[\"val_recall\"],\n","                                                                    results[\"val_f1_score\"]):\n","            csvwriter.writerow([epoch, train_loss, train_acc, val_loss, val_acc])\n","\n","    # Save model\n","    torch.save(model.state_dict(), model_save_path)\n","    torch.save(model, model_save_path)\n","\n","    return results\n"],"metadata":{"id":"mJy66qc6NrM0","executionInfo":{"status":"ok","timestamp":1703953656003,"user_tz":0,"elapsed":35,"user":{"displayName":"Sukriti Dhang","userId":"17489705121618565895"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["# Create optimizer and loss function\n","optimizer = torch.optim.Adam(params=pretrained_vit_addtn.parameters(),\n","                              lr=0.0001,#,  # Adjust the learning rate\n","    weight_decay=0.0001)#lr=1e-3,\n","loss_fn = torch.nn.CrossEntropyLoss()\n","'''\n","early_stopping_callback = keras.callbacks.EarlyStopping(\n","          monitor='val_accuracy',\n","          patience= 10,  # Number of epochs with no improvement after which training will be stopped\n","          mode='max',  # 'max' if the monitored metric should be maximized, 'min' if minimized\n","          verbose=1\n",")\n","'''\n","\n","# Train the classifier head of the pretrained ViT feature extractor model\n","#set_seeds()\n","pretrained_vit_results = train(model=pretrained_vit_addtn,\n","                                      train_dataloader=train_dataloader_pretrained,\n","                                      val_dataloader=val_dataloader_pretrained,\n","                                      optimizer=optimizer,\n","                                      loss_fn=loss_fn,\n","                                      epochs=10,\n","                                      result_csv_path='/python_programming/FYP_2022/viadnet/model/pretrained_vit_results_addtn_lsacprf.csv',\n","                                      model_save_path='/python_programming/FYP_2022/viadnet/model/viadnet_addtn_lsacprf.pt')#"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":974},"id":"oxKHy9-IVIrw","outputId":"c5855d3f-51d3-4281-ca48-3497c59c960d","executionInfo":{"status":"error","timestamp":1703961758600,"user_tz":0,"elapsed":8100041,"user":{"displayName":"Sukriti Dhang","userId":"17489705121618565895"}}},"execution_count":11,"outputs":[{"output_type":"stream","name":"stderr","text":[" 10%|███████▉                                                                       | 1/10 [27:15<4:05:17, 1635.27s/it]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1 | train_loss: 0.1431 | train_acc: 0.9680 | train_precision:0.9795 |train_recall:0.9560 |train_f1_score:0.9676 |val_loss: 0.1620 | val_acc: 0.9524 |val_precision:0.9380 |val_recall:0.9680 |val_f1_score:0.9528\n"]},{"output_type":"stream","name":"stderr","text":["\r 20%|███████████████▊                                                               | 2/10 [54:12<3:36:35, 1624.45s/it]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2 | train_loss: 0.0284 | train_acc: 0.9945 | train_precision:0.9930 |train_recall:0.9960 |train_f1_score:0.9945 |val_loss: 0.1284 | val_acc: 0.9544 |val_precision:0.9365 |val_recall:0.9740 |val_f1_score:0.9549\n"]},{"output_type":"stream","name":"stderr","text":["\r 30%|███████████████████████                                                      | 3/10 [1:14:42<2:48:30, 1444.29s/it]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 3 | train_loss: 0.0151 | train_acc: 0.9965 | train_precision:0.9950 |train_recall:0.9980 |train_f1_score:0.9965 |val_loss: 0.1106 | val_acc: 0.9633 |val_precision:0.9495 |val_recall:0.9780 |val_f1_score:0.9635\n"]},{"output_type":"stream","name":"stderr","text":["\r 40%|██████████████████████████████▊                                              | 4/10 [1:23:13<1:47:36, 1076.06s/it]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 4 | train_loss: 0.0095 | train_acc: 0.9985 | train_precision:0.9980 |train_recall:0.9990 |train_f1_score:0.9985 |val_loss: 0.1336 | val_acc: 0.9554 |val_precision:0.9317 |val_recall:0.9820 |val_f1_score:0.9562\n"]},{"output_type":"stream","name":"stderr","text":["\r 50%|███████████████████████████████████████                                       | 5/10 [1:31:51<1:12:54, 874.81s/it]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 5 | train_loss: 0.0081 | train_acc: 0.9990 | train_precision:0.9980 |train_recall:1.0000 |train_f1_score:0.9990 |val_loss: 0.1289 | val_acc: 0.9583 |val_precision:0.9370 |val_recall:0.9820 |val_f1_score:0.9590\n"]},{"output_type":"stream","name":"stderr","text":["\r 60%|████████████████████████████████████████████████                                | 6/10 [1:40:31<50:16, 754.09s/it]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 6 | train_loss: 0.0041 | train_acc: 1.0000 | train_precision:1.0000 |train_recall:1.0000 |train_f1_score:1.0000 |val_loss: 0.1087 | val_acc: 0.9653 |val_precision:0.9497 |val_recall:0.9820 |val_f1_score:0.9656\n"]},{"output_type":"stream","name":"stderr","text":["\r 70%|████████████████████████████████████████████████████████                        | 7/10 [1:49:06<33:47, 675.93s/it]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 7 | train_loss: 0.0034 | train_acc: 1.0000 | train_precision:1.0000 |train_recall:1.0000 |train_f1_score:1.0000 |val_loss: 0.1233 | val_acc: 0.9603 |val_precision:0.9389 |val_recall:0.9840 |val_f1_score:0.9609\n"]},{"output_type":"stream","name":"stderr","text":["\r 80%|████████████████████████████████████████████████████████████████                | 8/10 [1:57:36<20:46, 623.01s/it]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 8 | train_loss: 0.0026 | train_acc: 1.0000 | train_precision:1.0000 |train_recall:1.0000 |train_f1_score:1.0000 |val_loss: 0.1103 | val_acc: 0.9623 |val_precision:0.9425 |val_recall:0.9840 |val_f1_score:0.9628\n"]},{"output_type":"stream","name":"stderr","text":["\r 90%|████████████████████████████████████████████████████████████████████████        | 9/10 [2:06:17<09:51, 591.15s/it]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 9 | train_loss: 0.0019 | train_acc: 1.0000 | train_precision:1.0000 |train_recall:1.0000 |train_f1_score:1.0000 |val_loss: 0.1107 | val_acc: 0.9633 |val_precision:0.9461 |val_recall:0.9820 |val_f1_score:0.9637\n"]},{"output_type":"stream","name":"stderr","text":["100%|███████████████████████████████████████████████████████████████████████████████| 10/10 [2:14:59<00:00, 809.93s/it]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 10 | train_loss: 0.0018 | train_acc: 1.0000 | train_precision:1.0000 |train_recall:1.0000 |train_f1_score:1.0000 |val_loss: 0.1393 | val_acc: 0.9593 |val_precision:0.9371 |val_recall:0.9840 |val_f1_score:0.9600\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[1;32mIn[11], line 17\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;124;03mearly_stopping_callback = keras.callbacks.EarlyStopping(\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;124;03m          monitor='val_accuracy',\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;124;03m)\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Train the classifier head of the pretrained ViT feature extractor model\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m#set_seeds()\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m pretrained_vit_results \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpretrained_vit_addtn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_dataloader_pretrained\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_dataloader_pretrained\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43mresult_csv_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/python_programming/FYP_2022/viadnet/model/pretrained_vit_results_addtn_lsacprf.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43mmodel_save_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/python_programming/FYP_2022/viadnet/model/viadnet_addtn_lsacprf.pt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n","Cell \u001b[1;32mIn[10], line 65\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, train_dataloader, val_dataloader, optimizer, loss_fn, epochs, result_csv_path, model_save_path)\u001b[0m\n\u001b[0;32m     63\u001b[0m     csvwriter \u001b[38;5;241m=\u001b[39m csv\u001b[38;5;241m.\u001b[39mwriter(csvfile)\n\u001b[0;32m     64\u001b[0m     csvwriter\u001b[38;5;241m.\u001b[39mwriterow([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrain Loss\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrain Acc\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVal Loss\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVal Acc\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m epoch, train_loss, train_acc, val_loss, val_acc \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, epochs \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m),\n\u001b[0;32m     66\u001b[0m                                                                 results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     67\u001b[0m                                                                 results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_acc\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     68\u001b[0m                                                                 results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_precision\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     69\u001b[0m                                                                 results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_recall\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     70\u001b[0m                                                                 results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_f1_score\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     71\u001b[0m                                                                 results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     72\u001b[0m                                                                 results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_acc\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     73\u001b[0m                                                                 results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_precision\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     74\u001b[0m                                                                 results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_recall\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     75\u001b[0m                                                                 results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_f1_score\u001b[39m\u001b[38;5;124m\"\u001b[39m]):\n\u001b[0;32m     76\u001b[0m         csvwriter\u001b[38;5;241m.\u001b[39mwriterow([epoch, train_loss, train_acc, val_loss, val_acc])\n\u001b[0;32m     78\u001b[0m \u001b[38;5;66;03m# Save model\u001b[39;00m\n","\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 5)"]}]},{"cell_type":"markdown","source":["Plot training data"],"metadata":{"id":"j6XLW3IAwIRH"}},{"cell_type":"code","source":["import pandas as pd\n","\n","# Plot loss curves of a model\n","def plot_loss_curves(data):\n","\n","    loss = data[\"Train Loss\"].values\n","    val_loss = data[\"Val Loss\"].values\n","\n","    accuracy = data[\"Train Acc\"].values\n","    val_accuracy = data[\"Val Acc\"].values\n","\n","    print('accuracy:', accuracy)\n","    print('val_accuracy:', val_accuracy)\n","\n","    epochs = range(len(loss))\n","\n","    '''\n","    plt.figure(figsize=(15, 7))\n","\n","    # Plot loss\n","    plt.subplot(1, 2, 1)\n","    plt.plot(epochs, loss, label=\"train_loss\")\n","    plt.plot(epochs, test_loss, label=\"test_loss\")\n","    plt.title(\"Loss\")\n","    plt.xlabel(\"Epochs\")\n","    plt.legend()\n","\n","    # Plot accuracy\n","    plt.subplot(1, 2, 2)\n","    plt.plot(epochs, accuracy, label=\"train_accuracy\")\n","    plt.plot(epochs, test_accuracy, label=\"test_accuracy\")\n","    plt.title(\"Accuracy\")\n","    plt.xlabel(\"Epochs\")\n","    plt.legend()\n","    '''"],"metadata":{"id":"NtrJ1JPID_Al"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Plot the loss curves\n","data = pd.read_csv('/python_programming/FYP_2022/viadnet/pretrained_vit_results0.csv')\n","\n","plot_loss_curves(data)"],"metadata":{"id":"2uvcjoUNlO0G","executionInfo":{"status":"ok","timestamp":1702059830413,"user_tz":0,"elapsed":14,"user":{"displayName":"Sukriti Dhang","userId":"17489705121618565895"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"51d19158-7ccc-4e9d-e4f3-5c1593447c8d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["accuracy: [0.99702381 0.99950397 1.         1.         1.         1.\n"," 1.         1.         1.         1.        ]\n","val_accuracy: [0.94345238 0.94940476 0.9484127  0.95138889 0.95238095 0.95634921\n"," 0.95734127 0.95833333 0.95734127 0.95734127]\n"]}]},{"cell_type":"markdown","source":["Prediction on test dataset"],"metadata":{"id":"lL0j6_pGuAyZ"}},{"cell_type":"code","source":["# Predict on a target image with a target model\n","import torch\n","import torchvision\n","from torchvision import transforms\n","#import matplotlib.pyplot as plt\n","\n","from typing import List, Tuple\n","\n","from PIL import Image\n","\n","def pred_and_plot_image(\n","    model: torch.nn.Module,\n","    class_names: List[str],\n","    image_path: str,\n","    image_name: str,\n","    image_size: Tuple[int, int] = (224, 224),\n","    transform: torchvision.transforms = None\n","):\n","\n","\n","    # Open image\n","    img = Image.open(image_path)\n","\n","    # Create transformation for image (if one doesn't exist)\n","    if transform is not None:\n","        image_transform = transform\n","    else:\n","        image_transform = transforms.Compose(\n","            [\n","                transforms.Resize(image_size),\n","                transforms.ToTensor(),\n","                transforms.Normalize(\n","                    mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]\n","                ),\n","            ]\n","        )\n","\n","    ### Predict on image ###\n","\n","    with torch.inference_mode():\n","        # Transform and add an extra dimension to image (model requires samples in [batch_size, color_channels, height, width])\n","        transformed_image = image_transform(img).unsqueeze(dim=0)\n","\n","        # Make a prediction on image with an extra dimension and send it to the target device\n","        target_image_pred = model(transformed_image)#.to(device))\n","\n","    # Convert logits -> prediction probabilities (using torch.softmax() for multi-class classification)\n","    target_image_pred_probs = torch.softmax(target_image_pred, dim=1)#torch.softmax(target_image_pred, dim=1)\n","    target_image_pred_probsval = target_image_pred_probs.max().item()\n","\n","    # Convert prediction probabilities -> prediction labels\n","    target_image_pred_label = torch.argmax(target_image_pred_probs, dim=1).item()\n","\n","    target_image_pred_classname = class_names[target_image_pred_label]\n","\n","    #print('Pred:', class_names[target_image_pred_label], '|',  'Prob:', target_image_pred_probs.max():.3f)\n","    print('image name:', image_name, '|', 'Pred label:', target_image_pred_label, '|', 'pred prob:', round(target_image_pred_probsval,3), '|', 'class name:', target_image_pred_classname)\n","\n","    #csvwriter.writerow([\"Image_name\", \"Pred label\", \"Pred Prob\"])\n"," # Save results to CSV\n","    with open('/python_programming/FYP_2022/viadnet/testresult_vit.csv', 'a', newline='') as csvfile:\n","        csvwriter = csv.writer(csvfile)\n","        csvwriter.writerow([image_name, target_image_pred_label, round(target_image_pred_probsval,3), class_name])\n"],"metadata":{"id":"MakAQXjDuQiC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_image_path = \"/python_programming/FYP_2022/billboard_dataset/test/Billboard/scene_1501.jpg\"\n","\n","#class_names = ['Billbord', 'No-billboard'] #0, 1\n","\n","# Predict on test image\n","pred_and_plot_image(model=pretrained_vit,\n","                    image_path=test_image_path,\n","                    class_names=class_names)\n","\n","test_image_path = \"/python_programming/FYP_2022/billboard_dataset/test/No_Billboard/scene_1501.jpg\"\n","\n","#class_names = ['Billbord', 'No-billboard'] #0, 1\n","\n","# Predict on test image\n","pred_and_plot_image(model=pretrained_vit,\n","                    image_path=test_image_path,\n","                    class_names=class_names)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gFoAByQ9sNwb","executionInfo":{"status":"ok","timestamp":1702060218441,"user_tz":0,"elapsed":1143,"user":{"displayName":"Sukriti Dhang","userId":"17489705121618565895"}},"outputId":"1f88fdbe-b1b9-4d13-ea21-e131f24cf885"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Pred label: tensor([0]) | pred prob: tensor(0.9648)\n","Pred label: tensor([1]) | pred prob: tensor(0.9979)\n"]}]},{"cell_type":"code","source":["\n","import os\n","def pred_on_directory(model, class_names, directory_path, file_extension=\".jpg\"):\n","    for filename in os.listdir(directory_path):\n","        if filename.endswith(file_extension):\n","            image_path = os.path.join(directory_path, filename)\n","            image_name = os.path.basename(image_path)\n","            #print('image name:', image_name)\n","            pred_and_plot_image(model, class_names, image_path, image_name)\n","\n","# Directory path for test images\n","test_directory_path = \"/python_programming/FYP_2022/billboard_dataset/test/Billboard\"\n","\n","# Predict on the whole test directory\n","pred_on_directory(model=pretrained_vit,\n","                  class_names=class_names,\n","                  directory_path=test_directory_path)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dYhQ5TFtsiY7","executionInfo":{"status":"ok","timestamp":1702062323313,"user_tz":0,"elapsed":117215,"user":{"displayName":"Sukriti Dhang","userId":"17489705121618565895"}},"outputId":"44e99589-5a49-4313-bd26-f852d9025f92"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["image name: scene_1501.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9648)\n","image name: scene_1502.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9169)\n","image name: scene_1503.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9868)\n","image name: scene_1504.jpg | Pred label: tensor([0]) | pred prob: tensor(0.5799)\n","image name: scene_1505.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9916)\n","image name: scene_1506.jpg | Pred label: tensor([0]) | pred prob: tensor(0.8660)\n","image name: scene_1507.jpg | Pred label: tensor([1]) | pred prob: tensor(0.6926)\n","image name: scene_1508.jpg | Pred label: tensor([0]) | pred prob: tensor(0.8000)\n","image name: scene_1509.jpg | Pred label: tensor([1]) | pred prob: tensor(0.9907)\n","image name: scene_1510.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9908)\n","image name: scene_1511.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9997)\n","image name: scene_1512.jpg | Pred label: tensor([0]) | pred prob: tensor(0.6167)\n","image name: scene_1513.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9569)\n","image name: scene_1514.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9430)\n","image name: scene_1515.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9802)\n","image name: scene_1516.jpg | Pred label: tensor([0]) | pred prob: tensor(0.6473)\n","image name: scene_1517.jpg | Pred label: tensor([0]) | pred prob: tensor(1.0000)\n","image name: scene_1518.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9995)\n","image name: scene_1519.jpg | Pred label: tensor([0]) | pred prob: tensor(0.7407)\n","image name: scene_1520.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9704)\n","image name: scene_1521.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9041)\n","image name: scene_1522.jpg | Pred label: tensor([1]) | pred prob: tensor(0.9555)\n","image name: scene_1523.jpg | Pred label: tensor([0]) | pred prob: tensor(0.6931)\n","image name: scene_1524.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9987)\n","image name: scene_1525.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9995)\n","image name: scene_1526.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9999)\n","image name: scene_1527.jpg | Pred label: tensor([0]) | pred prob: tensor(0.8879)\n","image name: scene_1528.jpg | Pred label: tensor([0]) | pred prob: tensor(0.5861)\n","image name: scene_1529.jpg | Pred label: tensor([1]) | pred prob: tensor(0.9282)\n","image name: scene_1530.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9874)\n","image name: scene_1531.jpg | Pred label: tensor([1]) | pred prob: tensor(0.7132)\n","image name: scene_1532.jpg | Pred label: tensor([1]) | pred prob: tensor(0.9724)\n","image name: scene_1533.jpg | Pred label: tensor([1]) | pred prob: tensor(0.9997)\n","image name: scene_1534.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9772)\n","image name: scene_1535.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9702)\n","image name: scene_1536.jpg | Pred label: tensor([0]) | pred prob: tensor(0.8795)\n","image name: scene_1537.jpg | Pred label: tensor([1]) | pred prob: tensor(0.9991)\n","image name: scene_1538.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9870)\n","image name: scene_1539.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9770)\n","image name: scene_1540.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9975)\n","image name: scene_1541.jpg | Pred label: tensor([1]) | pred prob: tensor(0.8916)\n","image name: scene_1542.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9950)\n","image name: scene_1543.jpg | Pred label: tensor([0]) | pred prob: tensor(0.8819)\n","image name: scene_1544.jpg | Pred label: tensor([1]) | pred prob: tensor(0.9010)\n","image name: scene_1545.jpg | Pred label: tensor([0]) | pred prob: tensor(0.8984)\n","image name: scene_1546.jpg | Pred label: tensor([0]) | pred prob: tensor(1.0000)\n","image name: scene_1547.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9965)\n","image name: scene_1548.jpg | Pred label: tensor([0]) | pred prob: tensor(1.0000)\n","image name: scene_1549.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9354)\n","image name: scene_1550.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9306)\n","image name: scene_1551.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9796)\n","image name: scene_1552.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9934)\n","image name: scene_1553.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9761)\n","image name: scene_1554.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9907)\n","image name: scene_1555.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9983)\n","image name: scene_1556.jpg | Pred label: tensor([1]) | pred prob: tensor(0.9884)\n","image name: scene_1557.jpg | Pred label: tensor([0]) | pred prob: tensor(1.0000)\n","image name: scene_1558.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9987)\n","image name: scene_1559.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9999)\n","image name: scene_1560.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9194)\n","image name: scene_1561.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9876)\n","image name: scene_1562.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9193)\n","image name: scene_1563.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9963)\n","image name: scene_1564.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9089)\n","image name: scene_1565.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9990)\n","image name: scene_1566.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9855)\n","image name: scene_1567.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9936)\n","image name: scene_1568.jpg | Pred label: tensor([0]) | pred prob: tensor(1.0000)\n","image name: scene_1569.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9996)\n","image name: scene_1570.jpg | Pred label: tensor([0]) | pred prob: tensor(0.8055)\n","image name: scene_1571.jpg | Pred label: tensor([1]) | pred prob: tensor(0.8330)\n","image name: scene_1572.jpg | Pred label: tensor([1]) | pred prob: tensor(0.5921)\n","image name: scene_1573.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9992)\n","image name: scene_1574.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9996)\n","image name: scene_1575.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9914)\n","image name: scene_1576.jpg | Pred label: tensor([0]) | pred prob: tensor(1.)\n","image name: scene_1577.jpg | Pred label: tensor([1]) | pred prob: tensor(0.9132)\n","image name: scene_1578.jpg | Pred label: tensor([0]) | pred prob: tensor(1.0000)\n","image name: scene_1579.jpg | Pred label: tensor([0]) | pred prob: tensor(1.0000)\n","image name: scene_1580.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9999)\n","image name: scene_1581.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9987)\n","image name: scene_1582.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9978)\n","image name: scene_1583.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9999)\n","image name: scene_1584.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9999)\n","image name: scene_1585.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9764)\n","image name: scene_1586.jpg | Pred label: tensor([1]) | pred prob: tensor(0.7881)\n","image name: scene_1587.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9750)\n","image name: scene_1588.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9894)\n","image name: scene_1589.jpg | Pred label: tensor([0]) | pred prob: tensor(1.0000)\n","image name: scene_1590.jpg | Pred label: tensor([0]) | pred prob: tensor(1.0000)\n","image name: scene_1591.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9989)\n","image name: scene_1592.jpg | Pred label: tensor([0]) | pred prob: tensor(0.8295)\n","image name: scene_1593.jpg | Pred label: tensor([0]) | pred prob: tensor(0.8889)\n","image name: scene_1594.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9611)\n","image name: scene_1595.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9936)\n","image name: scene_1596.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9465)\n","image name: scene_1597.jpg | Pred label: tensor([1]) | pred prob: tensor(0.6670)\n","image name: scene_1598.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9898)\n","image name: scene_1599.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9725)\n","image name: scene_1600.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9893)\n","image name: scene_1601.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9963)\n","image name: scene_1602.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9999)\n","image name: scene_1603.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9980)\n","image name: scene_1604.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9822)\n","image name: scene_1605.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9995)\n","image name: scene_1606.jpg | Pred label: tensor([0]) | pred prob: tensor(1.0000)\n","image name: scene_1607.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9980)\n","image name: scene_1608.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9281)\n","image name: scene_1609.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9985)\n","image name: scene_1610.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9993)\n","image name: scene_1611.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9981)\n","image name: scene_1612.jpg | Pred label: tensor([0]) | pred prob: tensor(0.8337)\n","image name: scene_1613.jpg | Pred label: tensor([1]) | pred prob: tensor(0.9775)\n","image name: scene_1614.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9985)\n","image name: scene_1615.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9984)\n","image name: scene_1616.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9939)\n","image name: scene_1617.jpg | Pred label: tensor([0]) | pred prob: tensor(0.6485)\n","image name: scene_1618.jpg | Pred label: tensor([1]) | pred prob: tensor(0.6978)\n","image name: scene_1619.jpg | Pred label: tensor([0]) | pred prob: tensor(1.0000)\n","image name: scene_1620.jpg | Pred label: tensor([1]) | pred prob: tensor(0.9658)\n","image name: scene_1621.jpg | Pred label: tensor([0]) | pred prob: tensor(1.0000)\n","image name: scene_1622.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9963)\n","image name: scene_1623.jpg | Pred label: tensor([0]) | pred prob: tensor(0.7500)\n","image name: scene_1624.jpg | Pred label: tensor([0]) | pred prob: tensor(1.0000)\n","image name: scene_1625.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9671)\n","image name: scene_1626.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9984)\n","image name: scene_1627.jpg | Pred label: tensor([1]) | pred prob: tensor(0.8330)\n","image name: scene_1628.jpg | Pred label: tensor([1]) | pred prob: tensor(0.7325)\n","image name: scene_1629.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9977)\n","image name: scene_1630.jpg | Pred label: tensor([1]) | pred prob: tensor(0.6532)\n","image name: scene_1631.jpg | Pred label: tensor([0]) | pred prob: tensor(0.7717)\n","image name: scene_1632.jpg | Pred label: tensor([0]) | pred prob: tensor(0.8167)\n","image name: scene_1633.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9920)\n","image name: scene_1634.jpg | Pred label: tensor([1]) | pred prob: tensor(0.9768)\n","image name: scene_1635.jpg | Pred label: tensor([0]) | pred prob: tensor(1.0000)\n","image name: scene_1636.jpg | Pred label: tensor([1]) | pred prob: tensor(0.5420)\n","image name: scene_1637.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9975)\n","image name: scene_1638.jpg | Pred label: tensor([1]) | pred prob: tensor(0.7962)\n","image name: scene_1639.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9990)\n","image name: scene_1640.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9474)\n","image name: scene_1641.jpg | Pred label: tensor([0]) | pred prob: tensor(0.5850)\n","image name: scene_1642.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9915)\n","image name: scene_1643.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9999)\n","image name: scene_1644.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9936)\n","image name: scene_1645.jpg | Pred label: tensor([1]) | pred prob: tensor(0.9653)\n","image name: scene_1646.jpg | Pred label: tensor([1]) | pred prob: tensor(0.8324)\n","image name: scene_1647.jpg | Pred label: tensor([0]) | pred prob: tensor(1.0000)\n","image name: scene_1648.jpg | Pred label: tensor([1]) | pred prob: tensor(0.8828)\n","image name: scene_1649.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9564)\n","image name: scene_1650.jpg | Pred label: tensor([0]) | pred prob: tensor(1.0000)\n","image name: scene_1651.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9356)\n","image name: scene_1652.jpg | Pred label: tensor([1]) | pred prob: tensor(0.9094)\n","image name: scene_1653.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9998)\n","image name: scene_1654.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9994)\n","image name: scene_1655.jpg | Pred label: tensor([1]) | pred prob: tensor(0.8170)\n","image name: scene_1656.jpg | Pred label: tensor([1]) | pred prob: tensor(0.5921)\n","image name: scene_1657.jpg | Pred label: tensor([0]) | pred prob: tensor(1.0000)\n","image name: scene_1658.jpg | Pred label: tensor([0]) | pred prob: tensor(1.0000)\n","image name: scene_1659.jpg | Pred label: tensor([0]) | pred prob: tensor(0.7035)\n","image name: scene_1660.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9995)\n","image name: scene_1661.jpg | Pred label: tensor([0]) | pred prob: tensor(0.6405)\n","image name: scene_1662.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9999)\n","image name: scene_1663.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9600)\n","image name: scene_1664.jpg | Pred label: tensor([0]) | pred prob: tensor(1.0000)\n","image name: scene_1665.jpg | Pred label: tensor([0]) | pred prob: tensor(0.7646)\n","image name: scene_1666.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9781)\n","image name: scene_1667.jpg | Pred label: tensor([1]) | pred prob: tensor(0.9995)\n","image name: scene_1668.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9997)\n","image name: scene_1669.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9982)\n","image name: scene_1670.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9854)\n","image name: scene_1671.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9991)\n","image name: scene_1672.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9997)\n","image name: scene_1673.jpg | Pred label: tensor([1]) | pred prob: tensor(0.5386)\n","image name: scene_1674.jpg | Pred label: tensor([0]) | pred prob: tensor(0.8405)\n","image name: scene_1675.jpg | Pred label: tensor([0]) | pred prob: tensor(1.0000)\n","image name: scene_1676.jpg | Pred label: tensor([1]) | pred prob: tensor(0.9756)\n","image name: scene_1677.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9147)\n","image name: scene_1678.jpg | Pred label: tensor([0]) | pred prob: tensor(0.8067)\n","image name: scene_1679.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9979)\n","image name: scene_1680.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9663)\n","image name: scene_1681.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9971)\n","image name: scene_1682.jpg | Pred label: tensor([0]) | pred prob: tensor(0.6206)\n","image name: scene_1683.jpg | Pred label: tensor([0]) | pred prob: tensor(0.8516)\n","image name: scene_1684.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9993)\n","image name: scene_1685.jpg | Pred label: tensor([0]) | pred prob: tensor(0.5226)\n","image name: scene_1686.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9763)\n","image name: scene_1687.jpg | Pred label: tensor([1]) | pred prob: tensor(0.8709)\n","image name: scene_1688.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9317)\n","image name: scene_1689.jpg | Pred label: tensor([1]) | pred prob: tensor(0.5069)\n","image name: scene_1690.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9997)\n","image name: scene_1691.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9751)\n","image name: scene_1692.jpg | Pred label: tensor([0]) | pred prob: tensor(0.8271)\n","image name: scene_1693.jpg | Pred label: tensor([0]) | pred prob: tensor(0.7108)\n","image name: scene_1694.jpg | Pred label: tensor([0]) | pred prob: tensor(0.6278)\n","image name: scene_1695.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9815)\n","image name: scene_1696.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9918)\n","image name: scene_1697.jpg | Pred label: tensor([0]) | pred prob: tensor(1.0000)\n","image name: scene_1698.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9901)\n","image name: scene_1699.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9743)\n","image name: scene_1700.jpg | Pred label: tensor([1]) | pred prob: tensor(0.8704)\n","image name: scene_1701.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9997)\n","image name: scene_1702.jpg | Pred label: tensor([1]) | pred prob: tensor(0.9993)\n","image name: scene_1703.jpg | Pred label: tensor([0]) | pred prob: tensor(1.0000)\n","image name: scene_1704.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9929)\n","image name: scene_1705.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9185)\n","image name: scene_1706.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9991)\n","image name: scene_1707.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9995)\n","image name: scene_1708.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9841)\n","image name: scene_1709.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9669)\n","image name: scene_1710.jpg | Pred label: tensor([0]) | pred prob: tensor(0.6256)\n","image name: scene_1711.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9475)\n","image name: scene_1712.jpg | Pred label: tensor([1]) | pred prob: tensor(0.5162)\n","image name: scene_1713.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9862)\n","image name: scene_1714.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9997)\n","image name: scene_1715.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9997)\n","image name: scene_1716.jpg | Pred label: tensor([1]) | pred prob: tensor(0.6103)\n","image name: scene_1717.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9726)\n","image name: scene_1718.jpg | Pred label: tensor([1]) | pred prob: tensor(0.8336)\n","image name: scene_1719.jpg | Pred label: tensor([1]) | pred prob: tensor(0.9929)\n","image name: scene_1720.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9990)\n","image name: scene_1721.jpg | Pred label: tensor([1]) | pred prob: tensor(0.9970)\n","image name: scene_1722.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9999)\n","image name: scene_1723.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9980)\n","image name: scene_1724.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9979)\n","image name: scene_1725.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9742)\n","image name: scene_1726.jpg | Pred label: tensor([0]) | pred prob: tensor(0.6256)\n","image name: scene_1727.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9633)\n","image name: scene_1728.jpg | Pred label: tensor([0]) | pred prob: tensor(0.8805)\n","image name: scene_1729.jpg | Pred label: tensor([0]) | pred prob: tensor(0.8423)\n","image name: scene_1730.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9997)\n","image name: scene_1731.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9910)\n","image name: scene_1732.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9843)\n","image name: scene_1733.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9957)\n","image name: scene_1734.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9998)\n","image name: scene_1735.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9999)\n","image name: scene_1736.jpg | Pred label: tensor([0]) | pred prob: tensor(0.5345)\n","image name: scene_1737.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9978)\n","image name: scene_1738.jpg | Pred label: tensor([0]) | pred prob: tensor(0.6301)\n","image name: scene_1739.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9976)\n","image name: scene_1740.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9537)\n","image name: scene_1741.jpg | Pred label: tensor([1]) | pred prob: tensor(0.6801)\n","image name: scene_1742.jpg | Pred label: tensor([0]) | pred prob: tensor(0.7247)\n","image name: scene_1743.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9597)\n","image name: scene_1744.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9940)\n","image name: scene_1745.jpg | Pred label: tensor([1]) | pred prob: tensor(0.9212)\n","image name: scene_1746.jpg | Pred label: tensor([0]) | pred prob: tensor(0.5327)\n","image name: scene_1747.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9997)\n","image name: scene_1748.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9650)\n","image name: scene_1749.jpg | Pred label: tensor([1]) | pred prob: tensor(0.6752)\n","image name: scene_1750.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9954)\n"]}]},{"cell_type":"code","source":["import os\n","\n","def pred_on_directory(model, class_names, directory_path, file_extension=\".jpg\"):\n","    for filename in os.listdir(directory_path):\n","        if filename.endswith(file_extension):\n","            image_path = os.path.join(directory_path, filename)\n","            image_name = os.path.basename(image_path)\n","            #print('image name:', image_name)\n","            pred_and_plot_image(model, class_names, image_path, image_name)\n","\n","# Directory path for test images\n","test_directory_path = \"/python_programming/FYP_2022/billboard_dataset/test/No_Billboard\"\n","\n","# Predict on the whole test directory\n","pred_on_directory(model=pretrained_vit,\n","                  class_names=class_names,\n","                  directory_path=test_directory_path)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X9DQEU6Ct1AB","executionInfo":{"status":"ok","timestamp":1702062416740,"user_tz":0,"elapsed":56153,"user":{"displayName":"Sukriti Dhang","userId":"17489705121618565895"}},"outputId":"7fbb986f-cca7-4178-86f4-b96b55222280"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["image name: 0004.jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 0009.jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 0024.jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 0046.jpg | Pred label: tensor([1]) | pred prob: tensor(1.)\n","image name: 0068.jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 0075.jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 0083.jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 111.jpg | Pred label: tensor([1]) | pred prob: tensor(0.9989)\n","image name: 114.jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 115.jpg | Pred label: tensor([1]) | pred prob: tensor(0.9997)\n","image name: 12.jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 13 (2).jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 130.jpg | Pred label: tensor([1]) | pred prob: tensor(0.8815)\n","image name: 14 (2).jpg | Pred label: tensor([0]) | pred prob: tensor(0.5025)\n","image name: 140.jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 141 (2).jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 143 (3).jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 145 (3).jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 152.jpg | Pred label: tensor([1]) | pred prob: tensor(0.9804)\n","image name: 156 (2).jpg | Pred label: tensor([1]) | pred prob: tensor(0.9998)\n","image name: 156.jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 178 (2).jpg | Pred label: tensor([1]) | pred prob: tensor(1.)\n","image name: 179 (3).jpg | Pred label: tensor([1]) | pred prob: tensor(0.9969)\n","image name: 191.jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 196 (2).jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 200.jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 201 (2).jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 20162.jpg | Pred label: tensor([1]) | pred prob: tensor(0.9998)\n","image name: 20183.jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 20184.jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 20234.jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 20297.jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 20365.jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 20367.jpg | Pred label: tensor([1]) | pred prob: tensor(0.9999)\n","image name: 204 (2).jpg | Pred label: tensor([1]) | pred prob: tensor(0.9999)\n","image name: 20417.jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 205 (2).jpg | Pred label: tensor([1]) | pred prob: tensor(0.9998)\n","image name: 205.jpg | Pred label: tensor([1]) | pred prob: tensor(0.9919)\n","image name: 20652.jpg | Pred label: tensor([1]) | pred prob: tensor(0.9997)\n","image name: 20677.jpg | Pred label: tensor([1]) | pred prob: tensor(0.9990)\n","image name: 20719.jpg | Pred label: tensor([1]) | pred prob: tensor(0.9997)\n","image name: 210 (2).jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 210.jpg | Pred label: tensor([0]) | pred prob: tensor(0.5138)\n","image name: 21317.jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 21375.jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 21430.jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 21483.jpg | Pred label: tensor([1]) | pred prob: tensor(0.9957)\n","image name: 21587.jpg | Pred label: tensor([1]) | pred prob: tensor(0.9998)\n","image name: 21699.jpg | Pred label: tensor([1]) | pred prob: tensor(0.9997)\n","image name: 21900.jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 21956.jpg | Pred label: tensor([1]) | pred prob: tensor(0.9999)\n","image name: 22092.jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 221 (3).jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 22167.jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 22172.jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 22177.jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 22179.jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 22201.jpg | Pred label: tensor([1]) | pred prob: tensor(0.9996)\n","image name: 22299.jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 223.jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 22336.jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 224.jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 22400.jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 225 (2).jpg | Pred label: tensor([1]) | pred prob: tensor(0.9999)\n","image name: 22570.jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 22703.jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 22722.jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 22774.jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 22777.jpg | Pred label: tensor([1]) | pred prob: tensor(0.9960)\n","image name: 22819.jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 22837.jpg | Pred label: tensor([1]) | pred prob: tensor(0.9662)\n","image name: 22897.jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 22938.jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 22955.jpg | Pred label: tensor([1]) | pred prob: tensor(0.9994)\n","image name: 23101.jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 23107.jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 23122.jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 23160.jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 23186.jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 23309.jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 23344.jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 23390.jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 23473.jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 23486.jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 23491.jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 235.jpg | Pred label: tensor([1]) | pred prob: tensor(0.9999)\n","image name: 23502.jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 23573.jpg | Pred label: tensor([1]) | pred prob: tensor(0.9994)\n","image name: 23782.jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 23853.jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 266.jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 268.jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 27.jpg | Pred label: tensor([1]) | pred prob: tensor(0.9733)\n","image name: 28 (2).jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 3.jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 300.jpg | Pred label: tensor([1]) | pred prob: tensor(0.9998)\n","image name: 308 (2).jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 309.jpg | Pred label: tensor([1]) | pred prob: tensor(0.9999)\n","image name: 310 (2).jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 310.jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 334.jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 347.jpg | Pred label: tensor([1]) | pred prob: tensor(0.6369)\n","image name: 36.jpg | Pred label: tensor([1]) | pred prob: tensor(0.9999)\n","image name: 370.jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 38 (2).jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 38.jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 382.jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 387.jpg | Pred label: tensor([1]) | pred prob: tensor(0.9987)\n","image name: 395.jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 403.jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 410.jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 439.jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 44 (2).jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 455.jpg | Pred label: tensor([1]) | pred prob: tensor(0.9870)\n","image name: 458.jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 471 (2).jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 481.jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 500.jpg | Pred label: tensor([1]) | pred prob: tensor(0.9999)\n","image name: 508.jpg | Pred label: tensor([1]) | pred prob: tensor(0.9996)\n","image name: 521.jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 531.jpg | Pred label: tensor([1]) | pred prob: tensor(0.9988)\n","image name: 536.jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 568.jpg | Pred label: tensor([1]) | pred prob: tensor(0.9941)\n","image name: 57.jpg | Pred label: tensor([1]) | pred prob: tensor(0.9351)\n","image name: 592.jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 6.jpg | Pred label: tensor([1]) | pred prob: tensor(0.9979)\n","image name: 605.jpg | Pred label: tensor([1]) | pred prob: tensor(0.9995)\n","image name: 63 (2).jpg | Pred label: tensor([1]) | pred prob: tensor(0.9968)\n","image name: 630.jpg | Pred label: tensor([1]) | pred prob: tensor(0.9834)\n","image name: 64.jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 67.jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 69.jpg | Pred label: tensor([1]) | pred prob: tensor(0.9999)\n","image name: 71.jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 740.jpg | Pred label: tensor([1]) | pred prob: tensor(0.9999)\n","image name: 75.jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 77 (2).jpg | Pred label: tensor([1]) | pred prob: tensor(0.9999)\n","image name: 803.jpg | Pred label: tensor([1]) | pred prob: tensor(0.9997)\n","image name: 82 (2).jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 87.jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n"]}]},{"cell_type":"code","source":["def pred_on_directory(model, class_names, directory_path, file_extension=\".jpg\"):\n","    for filename in os.listdir(directory_path):\n","        if filename.endswith(file_extension):\n","            image_path = os.path.join(directory_path, filename)\n","            image_name = os.path.basename(image_path)\n","            #print('image name:', image_name)\n","            pred_and_plot_image(model, class_names, image_path, image_name)\n","\n","# Directory path for test images\n","test_directory_path = \"/python_programming/FYP_2022/billboard_dataset/test1\"\n","\n","# Predict on the whole test directory\n","pred_on_directory(model=pretrained_vit,\n","                  class_names=class_names,\n","                  directory_path=test_directory_path)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lhSUv6WM04Bv","executionInfo":{"status":"ok","timestamp":1702062610881,"user_tz":0,"elapsed":138797,"user":{"displayName":"Sukriti Dhang","userId":"17489705121618565895"}},"outputId":"993563d6-28a9-46d9-854e-0f4a2d034cab"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["image name: 0004.jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 0009.jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 0024.jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 0046.jpg | Pred label: tensor([1]) | pred prob: tensor(1.)\n","image name: 0068.jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 0075.jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 0083.jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 111.jpg | Pred label: tensor([1]) | pred prob: tensor(0.9989)\n","image name: 114.jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 115.jpg | Pred label: tensor([1]) | pred prob: tensor(0.9997)\n","image name: 12.jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 13 (2).jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 130.jpg | Pred label: tensor([1]) | pred prob: tensor(0.8815)\n","image name: 14 (2).jpg | Pred label: tensor([0]) | pred prob: tensor(0.5025)\n","image name: 140.jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 141 (2).jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 143 (3).jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 145 (3).jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 152.jpg | Pred label: tensor([1]) | pred prob: tensor(0.9804)\n","image name: 156 (2).jpg | Pred label: tensor([1]) | pred prob: tensor(0.9998)\n","image name: 156.jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 178 (2).jpg | Pred label: tensor([1]) | pred prob: tensor(1.)\n","image name: 179 (3).jpg | Pred label: tensor([1]) | pred prob: tensor(0.9969)\n","image name: 191.jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 196 (2).jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 200.jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 201 (2).jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 20162.jpg | Pred label: tensor([1]) | pred prob: tensor(0.9998)\n","image name: 20183.jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 20184.jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 20234.jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 20297.jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 20365.jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 20367.jpg | Pred label: tensor([1]) | pred prob: tensor(0.9999)\n","image name: 204 (2).jpg | Pred label: tensor([1]) | pred prob: tensor(0.9999)\n","image name: 20417.jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 205 (2).jpg | Pred label: tensor([1]) | pred prob: tensor(0.9998)\n","image name: 205.jpg | Pred label: tensor([1]) | pred prob: tensor(0.9919)\n","image name: 20652.jpg | Pred label: tensor([1]) | pred prob: tensor(0.9997)\n","image name: 20677.jpg | Pred label: tensor([1]) | pred prob: tensor(0.9990)\n","image name: 20719.jpg | Pred label: tensor([1]) | pred prob: tensor(0.9997)\n","image name: 210 (2).jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 210.jpg | Pred label: tensor([0]) | pred prob: tensor(0.5138)\n","image name: 21317.jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 21375.jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 21430.jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 21483.jpg | Pred label: tensor([1]) | pred prob: tensor(0.9957)\n","image name: 21587.jpg | Pred label: tensor([1]) | pred prob: tensor(0.9998)\n","image name: 21699.jpg | Pred label: tensor([1]) | pred prob: tensor(0.9997)\n","image name: 21900.jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 21956.jpg | Pred label: tensor([1]) | pred prob: tensor(0.9999)\n","image name: 22092.jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 221 (3).jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 22167.jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 22172.jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 22177.jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 22179.jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 22201.jpg | Pred label: tensor([1]) | pred prob: tensor(0.9996)\n","image name: 22299.jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 223.jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 22336.jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 224.jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 22400.jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 225 (2).jpg | Pred label: tensor([1]) | pred prob: tensor(0.9999)\n","image name: 22570.jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 22703.jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 22722.jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 22774.jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 22777.jpg | Pred label: tensor([1]) | pred prob: tensor(0.9960)\n","image name: 22819.jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 22837.jpg | Pred label: tensor([1]) | pred prob: tensor(0.9662)\n","image name: 22897.jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 22938.jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 22955.jpg | Pred label: tensor([1]) | pred prob: tensor(0.9994)\n","image name: 23101.jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 23107.jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 23122.jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 23160.jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 23186.jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 23309.jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 23344.jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 23390.jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 23473.jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 23486.jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 23491.jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 235.jpg | Pred label: tensor([1]) | pred prob: tensor(0.9999)\n","image name: 23502.jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 23573.jpg | Pred label: tensor([1]) | pred prob: tensor(0.9994)\n","image name: 23782.jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 23853.jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 266.jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 268.jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 27.jpg | Pred label: tensor([1]) | pred prob: tensor(0.9733)\n","image name: 28 (2).jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 3.jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 300.jpg | Pred label: tensor([1]) | pred prob: tensor(0.9998)\n","image name: 308 (2).jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 309.jpg | Pred label: tensor([1]) | pred prob: tensor(0.9999)\n","image name: 310 (2).jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 310.jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 334.jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 347.jpg | Pred label: tensor([1]) | pred prob: tensor(0.6369)\n","image name: 36.jpg | Pred label: tensor([1]) | pred prob: tensor(0.9999)\n","image name: 370.jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 38 (2).jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 38.jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 382.jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 387.jpg | Pred label: tensor([1]) | pred prob: tensor(0.9987)\n","image name: 395.jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 403.jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 410.jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 439.jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 44 (2).jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 455.jpg | Pred label: tensor([1]) | pred prob: tensor(0.9870)\n","image name: 458.jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 471 (2).jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 481.jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 500.jpg | Pred label: tensor([1]) | pred prob: tensor(0.9999)\n","image name: 508.jpg | Pred label: tensor([1]) | pred prob: tensor(0.9996)\n","image name: 521.jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 531.jpg | Pred label: tensor([1]) | pred prob: tensor(0.9988)\n","image name: 536.jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 568.jpg | Pred label: tensor([1]) | pred prob: tensor(0.9941)\n","image name: 57.jpg | Pred label: tensor([1]) | pred prob: tensor(0.9351)\n","image name: 592.jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 6.jpg | Pred label: tensor([1]) | pred prob: tensor(0.9979)\n","image name: 605.jpg | Pred label: tensor([1]) | pred prob: tensor(0.9995)\n","image name: 63 (2).jpg | Pred label: tensor([1]) | pred prob: tensor(0.9968)\n","image name: 630.jpg | Pred label: tensor([1]) | pred prob: tensor(0.9834)\n","image name: 64.jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 67.jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 69.jpg | Pred label: tensor([1]) | pred prob: tensor(0.9999)\n","image name: 71.jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 740.jpg | Pred label: tensor([1]) | pred prob: tensor(0.9999)\n","image name: 75.jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 77 (2).jpg | Pred label: tensor([1]) | pred prob: tensor(0.9999)\n","image name: 803.jpg | Pred label: tensor([1]) | pred prob: tensor(0.9997)\n","image name: 82 (2).jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: 87.jpg | Pred label: tensor([1]) | pred prob: tensor(1.0000)\n","image name: scene_1501.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9648)\n","image name: scene_1502.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9169)\n","image name: scene_1503.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9868)\n","image name: scene_1504.jpg | Pred label: tensor([0]) | pred prob: tensor(0.5799)\n","image name: scene_1505.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9916)\n","image name: scene_1506.jpg | Pred label: tensor([0]) | pred prob: tensor(0.8660)\n","image name: scene_1507.jpg | Pred label: tensor([1]) | pred prob: tensor(0.6926)\n","image name: scene_1508.jpg | Pred label: tensor([0]) | pred prob: tensor(0.8000)\n","image name: scene_1509.jpg | Pred label: tensor([1]) | pred prob: tensor(0.9907)\n","image name: scene_1510.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9908)\n","image name: scene_1511.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9997)\n","image name: scene_1512.jpg | Pred label: tensor([0]) | pred prob: tensor(0.6167)\n","image name: scene_1513.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9569)\n","image name: scene_1514.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9430)\n","image name: scene_1515.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9802)\n","image name: scene_1516.jpg | Pred label: tensor([0]) | pred prob: tensor(0.6473)\n","image name: scene_1517.jpg | Pred label: tensor([0]) | pred prob: tensor(1.0000)\n","image name: scene_1518.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9995)\n","image name: scene_1519.jpg | Pred label: tensor([0]) | pred prob: tensor(0.7407)\n","image name: scene_1520.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9704)\n","image name: scene_1521.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9041)\n","image name: scene_1522.jpg | Pred label: tensor([1]) | pred prob: tensor(0.9555)\n","image name: scene_1523.jpg | Pred label: tensor([0]) | pred prob: tensor(0.6931)\n","image name: scene_1524.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9987)\n","image name: scene_1525.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9995)\n","image name: scene_1526.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9999)\n","image name: scene_1527.jpg | Pred label: tensor([0]) | pred prob: tensor(0.8879)\n","image name: scene_1528.jpg | Pred label: tensor([0]) | pred prob: tensor(0.5861)\n","image name: scene_1529.jpg | Pred label: tensor([1]) | pred prob: tensor(0.9282)\n","image name: scene_1530.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9874)\n","image name: scene_1531.jpg | Pred label: tensor([1]) | pred prob: tensor(0.7132)\n","image name: scene_1532.jpg | Pred label: tensor([1]) | pred prob: tensor(0.9724)\n","image name: scene_1533.jpg | Pred label: tensor([1]) | pred prob: tensor(0.9997)\n","image name: scene_1534.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9772)\n","image name: scene_1535.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9702)\n","image name: scene_1536.jpg | Pred label: tensor([0]) | pred prob: tensor(0.8795)\n","image name: scene_1537.jpg | Pred label: tensor([1]) | pred prob: tensor(0.9991)\n","image name: scene_1538.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9870)\n","image name: scene_1539.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9770)\n","image name: scene_1540.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9975)\n","image name: scene_1541.jpg | Pred label: tensor([1]) | pred prob: tensor(0.8916)\n","image name: scene_1542.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9950)\n","image name: scene_1543.jpg | Pred label: tensor([0]) | pred prob: tensor(0.8819)\n","image name: scene_1544.jpg | Pred label: tensor([1]) | pred prob: tensor(0.9010)\n","image name: scene_1545.jpg | Pred label: tensor([0]) | pred prob: tensor(0.8984)\n","image name: scene_1546.jpg | Pred label: tensor([0]) | pred prob: tensor(1.0000)\n","image name: scene_1547.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9965)\n","image name: scene_1548.jpg | Pred label: tensor([0]) | pred prob: tensor(1.0000)\n","image name: scene_1549.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9354)\n","image name: scene_1550.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9306)\n","image name: scene_1551.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9796)\n","image name: scene_1552.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9934)\n","image name: scene_1553.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9761)\n","image name: scene_1554.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9907)\n","image name: scene_1555.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9983)\n","image name: scene_1556.jpg | Pred label: tensor([1]) | pred prob: tensor(0.9884)\n","image name: scene_1557.jpg | Pred label: tensor([0]) | pred prob: tensor(1.0000)\n","image name: scene_1558.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9987)\n","image name: scene_1559.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9999)\n","image name: scene_1560.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9194)\n","image name: scene_1561.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9876)\n","image name: scene_1562.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9193)\n","image name: scene_1563.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9963)\n","image name: scene_1564.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9089)\n","image name: scene_1565.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9990)\n","image name: scene_1566.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9855)\n","image name: scene_1567.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9936)\n","image name: scene_1568.jpg | Pred label: tensor([0]) | pred prob: tensor(1.0000)\n","image name: scene_1569.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9996)\n","image name: scene_1570.jpg | Pred label: tensor([0]) | pred prob: tensor(0.8055)\n","image name: scene_1571.jpg | Pred label: tensor([1]) | pred prob: tensor(0.8330)\n","image name: scene_1572.jpg | Pred label: tensor([1]) | pred prob: tensor(0.5921)\n","image name: scene_1573.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9992)\n","image name: scene_1574.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9996)\n","image name: scene_1575.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9914)\n","image name: scene_1576.jpg | Pred label: tensor([0]) | pred prob: tensor(1.)\n","image name: scene_1577.jpg | Pred label: tensor([1]) | pred prob: tensor(0.9132)\n","image name: scene_1578.jpg | Pred label: tensor([0]) | pred prob: tensor(1.0000)\n","image name: scene_1579.jpg | Pred label: tensor([0]) | pred prob: tensor(1.0000)\n","image name: scene_1580.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9999)\n","image name: scene_1581.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9987)\n","image name: scene_1582.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9978)\n","image name: scene_1583.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9999)\n","image name: scene_1584.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9999)\n","image name: scene_1585.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9764)\n","image name: scene_1586.jpg | Pred label: tensor([1]) | pred prob: tensor(0.7881)\n","image name: scene_1587.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9750)\n","image name: scene_1588.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9894)\n","image name: scene_1589.jpg | Pred label: tensor([0]) | pred prob: tensor(1.0000)\n","image name: scene_1590.jpg | Pred label: tensor([0]) | pred prob: tensor(1.0000)\n","image name: scene_1591.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9989)\n","image name: scene_1592.jpg | Pred label: tensor([0]) | pred prob: tensor(0.8295)\n","image name: scene_1593.jpg | Pred label: tensor([0]) | pred prob: tensor(0.8889)\n","image name: scene_1594.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9611)\n","image name: scene_1595.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9936)\n","image name: scene_1596.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9465)\n","image name: scene_1597.jpg | Pred label: tensor([1]) | pred prob: tensor(0.6670)\n","image name: scene_1598.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9898)\n","image name: scene_1599.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9725)\n","image name: scene_1600.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9893)\n","image name: scene_1601.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9963)\n","image name: scene_1602.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9999)\n","image name: scene_1603.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9980)\n","image name: scene_1604.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9822)\n","image name: scene_1605.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9995)\n","image name: scene_1606.jpg | Pred label: tensor([0]) | pred prob: tensor(1.0000)\n","image name: scene_1607.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9980)\n","image name: scene_1608.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9281)\n","image name: scene_1609.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9985)\n","image name: scene_1610.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9993)\n","image name: scene_1611.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9981)\n","image name: scene_1612.jpg | Pred label: tensor([0]) | pred prob: tensor(0.8337)\n","image name: scene_1613.jpg | Pred label: tensor([1]) | pred prob: tensor(0.9775)\n","image name: scene_1614.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9985)\n","image name: scene_1615.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9984)\n","image name: scene_1616.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9939)\n","image name: scene_1617.jpg | Pred label: tensor([0]) | pred prob: tensor(0.6485)\n","image name: scene_1618.jpg | Pred label: tensor([1]) | pred prob: tensor(0.6978)\n","image name: scene_1619.jpg | Pred label: tensor([0]) | pred prob: tensor(1.0000)\n","image name: scene_1620.jpg | Pred label: tensor([1]) | pred prob: tensor(0.9658)\n","image name: scene_1621.jpg | Pred label: tensor([0]) | pred prob: tensor(1.0000)\n","image name: scene_1622.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9963)\n","image name: scene_1623.jpg | Pred label: tensor([0]) | pred prob: tensor(0.7500)\n","image name: scene_1624.jpg | Pred label: tensor([0]) | pred prob: tensor(1.0000)\n","image name: scene_1625.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9671)\n","image name: scene_1626.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9984)\n","image name: scene_1627.jpg | Pred label: tensor([1]) | pred prob: tensor(0.8330)\n","image name: scene_1628.jpg | Pred label: tensor([1]) | pred prob: tensor(0.7325)\n","image name: scene_1629.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9977)\n","image name: scene_1630.jpg | Pred label: tensor([1]) | pred prob: tensor(0.6532)\n","image name: scene_1631.jpg | Pred label: tensor([0]) | pred prob: tensor(0.7717)\n","image name: scene_1632.jpg | Pred label: tensor([0]) | pred prob: tensor(0.8167)\n","image name: scene_1633.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9920)\n","image name: scene_1634.jpg | Pred label: tensor([1]) | pred prob: tensor(0.9768)\n","image name: scene_1635.jpg | Pred label: tensor([0]) | pred prob: tensor(1.0000)\n","image name: scene_1636.jpg | Pred label: tensor([1]) | pred prob: tensor(0.5420)\n","image name: scene_1637.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9975)\n","image name: scene_1638.jpg | Pred label: tensor([1]) | pred prob: tensor(0.7962)\n","image name: scene_1639.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9990)\n","image name: scene_1640.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9474)\n","image name: scene_1641.jpg | Pred label: tensor([0]) | pred prob: tensor(0.5850)\n","image name: scene_1642.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9915)\n","image name: scene_1643.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9999)\n","image name: scene_1644.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9936)\n","image name: scene_1645.jpg | Pred label: tensor([1]) | pred prob: tensor(0.9653)\n","image name: scene_1646.jpg | Pred label: tensor([1]) | pred prob: tensor(0.8324)\n","image name: scene_1647.jpg | Pred label: tensor([0]) | pred prob: tensor(1.0000)\n","image name: scene_1648.jpg | Pred label: tensor([1]) | pred prob: tensor(0.8828)\n","image name: scene_1649.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9564)\n","image name: scene_1650.jpg | Pred label: tensor([0]) | pred prob: tensor(1.0000)\n","image name: scene_1651.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9356)\n","image name: scene_1652.jpg | Pred label: tensor([1]) | pred prob: tensor(0.9094)\n","image name: scene_1653.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9998)\n","image name: scene_1654.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9994)\n","image name: scene_1655.jpg | Pred label: tensor([1]) | pred prob: tensor(0.8170)\n","image name: scene_1656.jpg | Pred label: tensor([1]) | pred prob: tensor(0.5921)\n","image name: scene_1657.jpg | Pred label: tensor([0]) | pred prob: tensor(1.0000)\n","image name: scene_1658.jpg | Pred label: tensor([0]) | pred prob: tensor(1.0000)\n","image name: scene_1659.jpg | Pred label: tensor([0]) | pred prob: tensor(0.7035)\n","image name: scene_1660.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9995)\n","image name: scene_1661.jpg | Pred label: tensor([0]) | pred prob: tensor(0.6405)\n","image name: scene_1662.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9999)\n","image name: scene_1663.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9600)\n","image name: scene_1664.jpg | Pred label: tensor([0]) | pred prob: tensor(1.0000)\n","image name: scene_1665.jpg | Pred label: tensor([0]) | pred prob: tensor(0.7646)\n","image name: scene_1666.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9781)\n","image name: scene_1667.jpg | Pred label: tensor([1]) | pred prob: tensor(0.9995)\n","image name: scene_1668.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9997)\n","image name: scene_1669.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9982)\n","image name: scene_1670.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9854)\n","image name: scene_1671.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9991)\n","image name: scene_1672.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9997)\n","image name: scene_1673.jpg | Pred label: tensor([1]) | pred prob: tensor(0.5386)\n","image name: scene_1674.jpg | Pred label: tensor([0]) | pred prob: tensor(0.8405)\n","image name: scene_1675.jpg | Pred label: tensor([0]) | pred prob: tensor(1.0000)\n","image name: scene_1676.jpg | Pred label: tensor([1]) | pred prob: tensor(0.9756)\n","image name: scene_1677.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9147)\n","image name: scene_1678.jpg | Pred label: tensor([0]) | pred prob: tensor(0.8067)\n","image name: scene_1679.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9979)\n","image name: scene_1680.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9663)\n","image name: scene_1681.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9971)\n","image name: scene_1682.jpg | Pred label: tensor([0]) | pred prob: tensor(0.6206)\n","image name: scene_1683.jpg | Pred label: tensor([0]) | pred prob: tensor(0.8516)\n","image name: scene_1684.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9993)\n","image name: scene_1685.jpg | Pred label: tensor([0]) | pred prob: tensor(0.5226)\n","image name: scene_1686.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9763)\n","image name: scene_1687.jpg | Pred label: tensor([1]) | pred prob: tensor(0.8709)\n","image name: scene_1688.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9317)\n","image name: scene_1689.jpg | Pred label: tensor([1]) | pred prob: tensor(0.5069)\n","image name: scene_1690.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9997)\n","image name: scene_1691.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9751)\n","image name: scene_1692.jpg | Pred label: tensor([0]) | pred prob: tensor(0.8271)\n","image name: scene_1693.jpg | Pred label: tensor([0]) | pred prob: tensor(0.7108)\n","image name: scene_1694.jpg | Pred label: tensor([0]) | pred prob: tensor(0.6278)\n","image name: scene_1695.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9815)\n","image name: scene_1696.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9918)\n","image name: scene_1697.jpg | Pred label: tensor([0]) | pred prob: tensor(1.0000)\n","image name: scene_1698.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9901)\n","image name: scene_1699.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9743)\n","image name: scene_1700.jpg | Pred label: tensor([1]) | pred prob: tensor(0.8704)\n","image name: scene_1701.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9997)\n","image name: scene_1702.jpg | Pred label: tensor([1]) | pred prob: tensor(0.9993)\n","image name: scene_1703.jpg | Pred label: tensor([0]) | pred prob: tensor(1.0000)\n","image name: scene_1704.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9929)\n","image name: scene_1705.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9185)\n","image name: scene_1706.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9991)\n","image name: scene_1707.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9995)\n","image name: scene_1708.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9841)\n","image name: scene_1709.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9669)\n","image name: scene_1710.jpg | Pred label: tensor([0]) | pred prob: tensor(0.6256)\n","image name: scene_1711.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9475)\n","image name: scene_1712.jpg | Pred label: tensor([1]) | pred prob: tensor(0.5162)\n","image name: scene_1713.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9862)\n","image name: scene_1714.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9997)\n","image name: scene_1715.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9997)\n","image name: scene_1716.jpg | Pred label: tensor([1]) | pred prob: tensor(0.6103)\n","image name: scene_1717.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9726)\n","image name: scene_1718.jpg | Pred label: tensor([1]) | pred prob: tensor(0.8336)\n","image name: scene_1719.jpg | Pred label: tensor([1]) | pred prob: tensor(0.9929)\n","image name: scene_1720.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9990)\n","image name: scene_1721.jpg | Pred label: tensor([1]) | pred prob: tensor(0.9970)\n","image name: scene_1722.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9999)\n","image name: scene_1723.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9980)\n","image name: scene_1724.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9979)\n","image name: scene_1725.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9742)\n","image name: scene_1726.jpg | Pred label: tensor([0]) | pred prob: tensor(0.6256)\n","image name: scene_1727.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9633)\n","image name: scene_1728.jpg | Pred label: tensor([0]) | pred prob: tensor(0.8805)\n","image name: scene_1729.jpg | Pred label: tensor([0]) | pred prob: tensor(0.8423)\n","image name: scene_1730.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9997)\n","image name: scene_1731.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9910)\n","image name: scene_1732.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9843)\n","image name: scene_1733.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9957)\n","image name: scene_1734.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9998)\n","image name: scene_1735.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9999)\n","image name: scene_1736.jpg | Pred label: tensor([0]) | pred prob: tensor(0.5345)\n","image name: scene_1737.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9978)\n","image name: scene_1738.jpg | Pred label: tensor([0]) | pred prob: tensor(0.6301)\n","image name: scene_1739.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9976)\n","image name: scene_1740.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9537)\n","image name: scene_1741.jpg | Pred label: tensor([1]) | pred prob: tensor(0.6801)\n","image name: scene_1742.jpg | Pred label: tensor([0]) | pred prob: tensor(0.7247)\n","image name: scene_1743.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9597)\n","image name: scene_1744.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9940)\n","image name: scene_1745.jpg | Pred label: tensor([1]) | pred prob: tensor(0.9212)\n","image name: scene_1746.jpg | Pred label: tensor([0]) | pred prob: tensor(0.5327)\n","image name: scene_1747.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9997)\n","image name: scene_1748.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9650)\n","image name: scene_1749.jpg | Pred label: tensor([1]) | pred prob: tensor(0.6752)\n","image name: scene_1750.jpg | Pred label: tensor([0]) | pred prob: tensor(0.9954)\n"]}]}]}